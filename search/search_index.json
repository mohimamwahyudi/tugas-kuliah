{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"selamat datang di halaman tugas komputasi numerik \u00b6 profil \u00b6 `NAMA : MOH. IMAM WAHYUDI `NIM :180411100007 `KELAS :komputasi numerik 4-D `JURUSAN : TEKNIK INFORMATIKA \u200b","title":"index"},{"location":"#selamat-datang-di-halaman-tugas-komputasi-numerik","text":"","title":"selamat datang di halaman tugas komputasi numerik"},{"location":"#profil","text":"`NAMA : MOH. IMAM WAHYUDI `NIM :180411100007 `KELAS :komputasi numerik 4-D `JURUSAN : TEKNIK INFORMATIKA \u200b","title":"profil"},{"location":"DECISION TREE/","text":"DECISION TREE \u00b6 decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan. CARA MEMBUAT DECISION TREE \u00b6 \u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S berikut contoh data yang akan dinrubah mrnjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 berikut cara membuat decision tree dengan code lab = LabelEncoder () df [ \"gender_n\" ] = lab . fit_transform ( df [ \"GENDER\" ]) df [ \"car_type_n\" ] = lab . fit_transform ( df [ \"CAR TIPE\" ]) df [ \"shirt_size_n\" ] = lab . fit_transform ( df [ \"SHIRT SIZE\" ]) df [ \"class_n\" ] = lab . fit_transform ( df [ \"CLASS\" ]) df . style . hide_index () df CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS gender_n car_type_n shirt_size_n class_n 0 1 M FAMILY SMALL C0 1 0 3 0 1 2 M SPORT MEDIUM C0 1 3 2 0 2 3 M SPORT MEDIUM C0 1 3 2 0 3 4 M SPORT LARGE C0 1 3 1 0 4 5 M SPORT EXTRA LARGE C0 1 3 0 0 5 6 M SPORT EXTRA LARGE C0 1 3 0 0 6 7 F SPORT SMALL C0 0 3 3 0 7 8 F SPORT SMALL C0 0 3 3 0 8 9 F SPORT MEDIUM C1 0 3 2 1 9 10 F LUXURY LARGE C1 0 2 1 1 10 11 M FAMILY LARGE C1 1 0 1 1 11 12 M FAMILY EXTRA LARGE C1 1 0 0 1 12 13 M FAMILY MEDIUM C1 1 0 2 1 13 14 M LUCURY EXTRA LARGE C1 1 1 0 1 14 15 F LUCURY SMALL C1 0 1 3 1 15 16 F LUCURY SMALL C1 0 1 3 1 16 17 F LUCURY MEDIUM C1 0 1 2 1 17 18 F LUCURY MEDIUM C1 0 1 2 1 18 19 F LUCURY MEDIUM C1 0 1 2 1 19 20 F LUCURY LARGE C1 0 1 1 1 inputs = df . drop ([ \"CASTEMER ID\" , \"GENDER\" , \"CAR TIPE\" , \"SHIRT SIZE\" , \"CLASS\" , \"class_n\" ], axis = \"columns\" ) target = df [ \"class_n\" ] model = DecisionTreeClassifier ( criterion = \"entropy\" , random_state = 100 ) model . fit ( inputs , target ) DecisionTreeClassifier ( class_weight = None , criterion = 'entropy' , max_depth = None , max_features = None , max_leaf_nodes = None , min_impurity_decrease = 0.0 , min_impurity_split = None , min_samples_leaf = 1 , min_samples_split = 2 , min_weight_fraction_leaf = 0.0 , presort = False , random_state = 100 , splitter = 'best' ) from matplotlib import pyplot as plt tree . plot_tree ( model . fit ( inputs , target ), max_depth = None , feature_names = [ \"Customer ID\" , \"Gender\" , \"Car Type\" , \"Shirt Size\" ], class_names = [ \"C0\" , \"C1\" ], label = \"all\" , filled = True , impurity = True , node_ids = True , proportion = True , rotate = True , rounded = True , precision = 3 , ax = None , fontsize = None ) [Text(167.4, 195.696, 'node #0\\nGender < = 1.5\\nentropy = 1.0\\nsamples = 100.0%\\nvalue = [0.5, 0.5]\\nclass = C0'), Text(125.55000000000001, 152.208, 'node #1\\nCar Type < = 0.5\\nentropy = 0.65\\nsamples = 60.0%\\nvalue = [0.167, 0.833]\\nclass = C1'), Text(83.7, 108.72, 'node #2\\nentropy = 0.0\\nsamples = 10.0%\\nvalue = [0.0, 1.0]\\nclass = C1'), Text(167.4, 108.72, 'node #3\\nGender < = 0.5\\nentropy = 0.722\\nsamples = 50.0%\\nvalue = [0.2, 0.8]\\nclass = C1'), Text(83.7, 65.232, 'node #4\\nCar Type < = 2.5\\nentropy = 0.918\\nsamples = 15.0%\\nvalue = [0.333, 0.667]\\nclass = C1'), Text(41.85, 21.744, 'node #5\\nentropy = 0.0\\nsamples = 10.0%\\nvalue = [0.0, 1.0]\\nclass = C1'), Text(125.55000000000001, 21.744, 'node #6\\nentropy = 0.0\\nsamples = 5.0%\\nvalue = [1.0, 0.0]\\nclass = C0'), Text(251.10000000000002, 65.232, 'node #7\\nCar Type < = 1.5\\nentropy = 0.592\\nsamples = 35.0%\\nvalue = [0.143, 0.857]\\nclass = C1'), Text(209.25, 21.744, 'node #8\\nentropy = 1.0\\nsamples = 10.0%\\nvalue = [0.5, 0.5]\\nclass = C0'), Text(292.95, 21.744, 'node #9\\nentropy = 0.0\\nsamples = 25.0%\\nvalue = [0.0, 1.0]\\nclass = C1'), Text(209.25, 152.208, 'node #10\\nentropy = 0.0\\nsamples = 40.0%\\nvalue = [1.0, 0.0]\\nclass = C0')] MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"DECISION TREE"},{"location":"DECISION TREE/#decision-tree","text":"decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan.","title":"DECISION TREE"},{"location":"DECISION TREE/#cara-membuat-decision-tree","text":"\u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S berikut contoh data yang akan dinrubah mrnjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 berikut cara membuat decision tree dengan code lab = LabelEncoder () df [ \"gender_n\" ] = lab . fit_transform ( df [ \"GENDER\" ]) df [ \"car_type_n\" ] = lab . fit_transform ( df [ \"CAR TIPE\" ]) df [ \"shirt_size_n\" ] = lab . fit_transform ( df [ \"SHIRT SIZE\" ]) df [ \"class_n\" ] = lab . fit_transform ( df [ \"CLASS\" ]) df . style . hide_index () df CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS gender_n car_type_n shirt_size_n class_n 0 1 M FAMILY SMALL C0 1 0 3 0 1 2 M SPORT MEDIUM C0 1 3 2 0 2 3 M SPORT MEDIUM C0 1 3 2 0 3 4 M SPORT LARGE C0 1 3 1 0 4 5 M SPORT EXTRA LARGE C0 1 3 0 0 5 6 M SPORT EXTRA LARGE C0 1 3 0 0 6 7 F SPORT SMALL C0 0 3 3 0 7 8 F SPORT SMALL C0 0 3 3 0 8 9 F SPORT MEDIUM C1 0 3 2 1 9 10 F LUXURY LARGE C1 0 2 1 1 10 11 M FAMILY LARGE C1 1 0 1 1 11 12 M FAMILY EXTRA LARGE C1 1 0 0 1 12 13 M FAMILY MEDIUM C1 1 0 2 1 13 14 M LUCURY EXTRA LARGE C1 1 1 0 1 14 15 F LUCURY SMALL C1 0 1 3 1 15 16 F LUCURY SMALL C1 0 1 3 1 16 17 F LUCURY MEDIUM C1 0 1 2 1 17 18 F LUCURY MEDIUM C1 0 1 2 1 18 19 F LUCURY MEDIUM C1 0 1 2 1 19 20 F LUCURY LARGE C1 0 1 1 1 inputs = df . drop ([ \"CASTEMER ID\" , \"GENDER\" , \"CAR TIPE\" , \"SHIRT SIZE\" , \"CLASS\" , \"class_n\" ], axis = \"columns\" ) target = df [ \"class_n\" ] model = DecisionTreeClassifier ( criterion = \"entropy\" , random_state = 100 ) model . fit ( inputs , target ) DecisionTreeClassifier ( class_weight = None , criterion = 'entropy' , max_depth = None , max_features = None , max_leaf_nodes = None , min_impurity_decrease = 0.0 , min_impurity_split = None , min_samples_leaf = 1 , min_samples_split = 2 , min_weight_fraction_leaf = 0.0 , presort = False , random_state = 100 , splitter = 'best' ) from matplotlib import pyplot as plt tree . plot_tree ( model . fit ( inputs , target ), max_depth = None , feature_names = [ \"Customer ID\" , \"Gender\" , \"Car Type\" , \"Shirt Size\" ], class_names = [ \"C0\" , \"C1\" ], label = \"all\" , filled = True , impurity = True , node_ids = True , proportion = True , rotate = True , rounded = True , precision = 3 , ax = None , fontsize = None ) [Text(167.4, 195.696, 'node #0\\nGender < = 1.5\\nentropy = 1.0\\nsamples = 100.0%\\nvalue = [0.5, 0.5]\\nclass = C0'), Text(125.55000000000001, 152.208, 'node #1\\nCar Type < = 0.5\\nentropy = 0.65\\nsamples = 60.0%\\nvalue = [0.167, 0.833]\\nclass = C1'), Text(83.7, 108.72, 'node #2\\nentropy = 0.0\\nsamples = 10.0%\\nvalue = [0.0, 1.0]\\nclass = C1'), Text(167.4, 108.72, 'node #3\\nGender < = 0.5\\nentropy = 0.722\\nsamples = 50.0%\\nvalue = [0.2, 0.8]\\nclass = C1'), Text(83.7, 65.232, 'node #4\\nCar Type < = 2.5\\nentropy = 0.918\\nsamples = 15.0%\\nvalue = [0.333, 0.667]\\nclass = C1'), Text(41.85, 21.744, 'node #5\\nentropy = 0.0\\nsamples = 10.0%\\nvalue = [0.0, 1.0]\\nclass = C1'), Text(125.55000000000001, 21.744, 'node #6\\nentropy = 0.0\\nsamples = 5.0%\\nvalue = [1.0, 0.0]\\nclass = C0'), Text(251.10000000000002, 65.232, 'node #7\\nCar Type < = 1.5\\nentropy = 0.592\\nsamples = 35.0%\\nvalue = [0.143, 0.857]\\nclass = C1'), Text(209.25, 21.744, 'node #8\\nentropy = 1.0\\nsamples = 10.0%\\nvalue = [0.5, 0.5]\\nclass = C0'), Text(292.95, 21.744, 'node #9\\nentropy = 0.0\\nsamples = 25.0%\\nvalue = [0.0, 1.0]\\nclass = C1'), Text(209.25, 152.208, 'node #10\\nentropy = 0.0\\nsamples = 40.0%\\nvalue = [1.0, 0.0]\\nclass = C0')] MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"CARA MEMBUAT DECISION TREE"},{"location":"Extrapolasi Richardsonp/","text":"Richardson Extrapolation \u00b6 Dalam analisis numerik, Richardson Extrapolation adalah metode percepatan urutan, yang digunakan untuk meningkatkan laju konvergensi suatu urutan. Richardson Extrapolation termasuk integrasi Romberg, yang menerapkan ekstrapolasi Richardson pada aturan trapesium, dan algoritma Bulirsch-Stoer untuk menyelesaikan persamaan diferensial biasa. Beda terpusat (Central Difference): $$ f^,(x) ={f(x+h)-f(x-h)\\over 2h}+ O (h^2) $$ Dapat kita mendapat formula terbaik ? Ditetapkan f (x) dan x tertentu: $$ \u00d8(h)={f(x+h)-f(x-h)\\over 2h} $$ $$ \u00d8(h)= f^, (x) - a_2 h^2 - a_4h^4-a_6h^6-..... $$ $$ \u00d8({h\\over 2}) = f^, (x)-a_2|{h\\over2}|^2-a_4|{h\\over4}|^4-a_6|{h\\over5}|^6 -.... $$ $$ \u00d8(h)-4\u00d8({h\\over2}) = -3f^,(x)-{3\\over4}a_4h^4-{15\\over16}a_6h^6-... $$ $$ => f^,(x) = {4\\over3}\u00d8({h\\over2})-{1\\over3}\u00d8(h)+O(h^4) $$ Contoh \u00b6 \u2022 Gunakan fungsi: \u200b $f(x)=-0.1x^4-0.15x^3-0.5x^2-0.25x+1.2$ \u200b Mulai dari $h_1=0.5$ dan $h_2=0.25$ hitung estimasi dengan $f^,(0.5)$ menggunakan richardson Extrapolation \u2022 nilai sesungguhnya $f^,(0.5)=-0.9125$ Solusi \u00b6 Turunan pertama dapat dihitung dengan beda terpusat ( centered differences) yaitu: $\u00d8(h)={f(0.5+h)-f(0.5-h)\\over 2h}$ pada x =0.5 $\u00d8(0.5)={f(1)-f(0)\\over 1}={0.2-1.2\\over1}=-1.0, |\u01b8_t|=2.4%$ Estimasi dapat di perbaiki dengan menggunakan : $f^,(0.5)={4\\over 3}\u00d8({h\\over2})-{1\\over3}\u00d8(h)={4\\over3}(-0.934375)-{1\\over3}(-1)=-0.9125$ yang menghasilkan nilai yang sama Tabel Richardson Extrapolation \u00b6 D(0,0) = \u00d8 (h) D(1,0) =\u00d8(h/2) D(11) D(2,0)=\u00d8(h/4) D(2,1) D(2,2) D(3,0)=\u00d8(h/8) D(3,1) D(3,2) D(3,3) from math import * def zeros ( n , m ): Z = [] for i in range ( n ): Z . append ([ 0 ] * m ) return Z def D ( Func , a , h ): return ( Func ( a + h ) - Func ( a - h )) / ( 2 * h ) def Richardson_dif ( func , a ): k = 9 L = zeros ( k , k ) for I in range ( k ): L [ I ][ 0 ] = D ( func , a , 1 / ( 2 ** ( I + 1 ))) for j in range ( 1 , k ): for i in range ( k - j ): L [ i ][ j ] = (( 4 ** ( j )) * L [ i + 1 ][ j - 1 ] - L [ i ][ j - 1 ]) / ( 4 ** ( j ) - 1 ) return L [ 0 ][ k - 1 ] print ( 'Numerical differentiation of Func=-0.1*x**4-0.15*x**3-0.5*x**2-0.25*x+1.2 at x=0.5' ) print ( ' %04.20f ' % Richardson_dif ( lambda x : - 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 , 0.5 )) print ( 'diff(2**cos(pi+sin(x)) at x=pi/2 is equal to = %04.20f ' % Richardson_dif ( lambda x : 2 ** cos ( pi + sin ( x )), pi / 3 )) Numerical differentiation of Func =- 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 at x = 0.5 - 0.91250000000000530687 diff ( 2 ** cos ( pi + sin ( x )) at x = pi / 2 is equal to = 0.16849558398154249050 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Extrapolasi Richardsonp"},{"location":"Extrapolasi Richardsonp/#richardson-extrapolation","text":"Dalam analisis numerik, Richardson Extrapolation adalah metode percepatan urutan, yang digunakan untuk meningkatkan laju konvergensi suatu urutan. Richardson Extrapolation termasuk integrasi Romberg, yang menerapkan ekstrapolasi Richardson pada aturan trapesium, dan algoritma Bulirsch-Stoer untuk menyelesaikan persamaan diferensial biasa. Beda terpusat (Central Difference): $$ f^,(x) ={f(x+h)-f(x-h)\\over 2h}+ O (h^2) $$ Dapat kita mendapat formula terbaik ? Ditetapkan f (x) dan x tertentu: $$ \u00d8(h)={f(x+h)-f(x-h)\\over 2h} $$ $$ \u00d8(h)= f^, (x) - a_2 h^2 - a_4h^4-a_6h^6-..... $$ $$ \u00d8({h\\over 2}) = f^, (x)-a_2|{h\\over2}|^2-a_4|{h\\over4}|^4-a_6|{h\\over5}|^6 -.... $$ $$ \u00d8(h)-4\u00d8({h\\over2}) = -3f^,(x)-{3\\over4}a_4h^4-{15\\over16}a_6h^6-... $$ $$ => f^,(x) = {4\\over3}\u00d8({h\\over2})-{1\\over3}\u00d8(h)+O(h^4) $$","title":"Richardson Extrapolation"},{"location":"Extrapolasi Richardsonp/#contoh","text":"\u2022 Gunakan fungsi: \u200b $f(x)=-0.1x^4-0.15x^3-0.5x^2-0.25x+1.2$ \u200b Mulai dari $h_1=0.5$ dan $h_2=0.25$ hitung estimasi dengan $f^,(0.5)$ menggunakan richardson Extrapolation \u2022 nilai sesungguhnya $f^,(0.5)=-0.9125$","title":"Contoh"},{"location":"Extrapolasi Richardsonp/#solusi","text":"Turunan pertama dapat dihitung dengan beda terpusat ( centered differences) yaitu: $\u00d8(h)={f(0.5+h)-f(0.5-h)\\over 2h}$ pada x =0.5 $\u00d8(0.5)={f(1)-f(0)\\over 1}={0.2-1.2\\over1}=-1.0, |\u01b8_t|=2.4%$ Estimasi dapat di perbaiki dengan menggunakan : $f^,(0.5)={4\\over 3}\u00d8({h\\over2})-{1\\over3}\u00d8(h)={4\\over3}(-0.934375)-{1\\over3}(-1)=-0.9125$ yang menghasilkan nilai yang sama","title":"Solusi"},{"location":"Extrapolasi Richardsonp/#tabel-richardson-extrapolation","text":"D(0,0) = \u00d8 (h) D(1,0) =\u00d8(h/2) D(11) D(2,0)=\u00d8(h/4) D(2,1) D(2,2) D(3,0)=\u00d8(h/8) D(3,1) D(3,2) D(3,3) from math import * def zeros ( n , m ): Z = [] for i in range ( n ): Z . append ([ 0 ] * m ) return Z def D ( Func , a , h ): return ( Func ( a + h ) - Func ( a - h )) / ( 2 * h ) def Richardson_dif ( func , a ): k = 9 L = zeros ( k , k ) for I in range ( k ): L [ I ][ 0 ] = D ( func , a , 1 / ( 2 ** ( I + 1 ))) for j in range ( 1 , k ): for i in range ( k - j ): L [ i ][ j ] = (( 4 ** ( j )) * L [ i + 1 ][ j - 1 ] - L [ i ][ j - 1 ]) / ( 4 ** ( j ) - 1 ) return L [ 0 ][ k - 1 ] print ( 'Numerical differentiation of Func=-0.1*x**4-0.15*x**3-0.5*x**2-0.25*x+1.2 at x=0.5' ) print ( ' %04.20f ' % Richardson_dif ( lambda x : - 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 , 0.5 )) print ( 'diff(2**cos(pi+sin(x)) at x=pi/2 is equal to = %04.20f ' % Richardson_dif ( lambda x : 2 ** cos ( pi + sin ( x )), pi / 3 )) Numerical differentiation of Func =- 0.1 * x ** 4 - 0.15 * x ** 3 - 0.5 * x ** 2 - 0.25 * x + 1.2 at x = 0.5 - 0.91250000000000530687 diff ( 2 ** cos ( pi + sin ( x )) at x = pi / 2 is equal to = 0.16849558398154249050 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tabel Richardson Extrapolation"},{"location":"Integrasi Numerik/","text":"https://mohimamwahyudi.github.io/Integrasi%20Numerik/ Integrasi Numerik \u00b6 metode rumberg \u00b6 Metode integrasi Romberg didasarkan pada perluasan ekstrapolasi Richardson untuk memperoleh nilai integrasi yang semakin baik. Sebagai catatan, setiap penerapan ekstrapolasi Richardson akan menaikkan order galat pada hasil solusinya sebesar dua: $O( h 2N ) \u2192 O(h 2 N+2 O( h ) \u2192 O(h )$. Misalnya,bila I(h) dan I(2h) dihitung dengan kaidah trapesium yang berorde galat O(h 2), maka ekstrapolasi Richardson menghaslkan kaidah Simpson 1/3 yang berorde O(h 4). Selanjutnya, bila I(h) dan I(2h) dihitung dengan kaidah Simpson 1/3, ekstrapolasi Richardson menghaslkan kaidah Boole yang berorde O(h 6). Tinjau kembali persamaan ekstrapolasi Richardson: $$ J = I(h)+{1(h)-I(2h)\\over(2^q -1)} $$ misalkan I adalah nilai integrasi yang di nyatakan sebagai I = Ak + Ch2 + Dh4 + Eh6 + ... yang dalam hal ini h=(b-a)/n dan ak = perkiraan nilai integrasi dengan kaidah trapesium dan jumlah pias $n = 2^k$ Gunakan A0, A1,...Ak pada persamaan ekstrapolasi Richardson untuk mendapatkan runtunan B1, B2, ...,Bk , yaitu $$ B_k = A_k + {A_k -A_k{_-1}\\over 2^2-1} $$ Jadi, nilai I (yang lebih baik) sekarang adalah I = Bk + D'h4 + E'h6 +\u2026 dengan orde galat Bk adalah O(h4). Selanjutnya, gunakan B1, B2 ,.., Bk pada persamaan ekstrapolasi Richardson untuk mendapatkan runtunan C2, C3,..., Ck, yaitu $$ C_k = B_K + {B_k - B_k{_-1}\\over 2^4-1} $$ Jadi, nilai I (yang lebih baik) sekarang adalah I = Ck + E \" h6 + ... dengan orde galat Ck adalah O(h6). Selanjutnya, gunakan C2, C3 ,..., Ck pada persamaan ekstrapolasi Richardson untuk mendapatkan runtunan D3 , D4 , ... , Dk , yaitu $$ D_k = C_k +{ C_k-C_k{_-1}\\over 2^6-1} $$ Jadi, nilai I (yang lebih baik) sekarang adalah I = Dk + E \"' h8 + ... dengan orde galat Dk adalah O(h8). Demikian seterusnya. Dari runtunan tersebut, diperoleh tabel yang dinamakan tabel Romberg seperti berikut ini listing program rumberg in python \u00b6 import numpy as np def trapezcomp ( f , a , b , n ): h = ( b - a ) / n x = a In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 def romberg ( f , a , b , p ): I = np . zeros (( p , p )) for k in range ( 0 , p ): # Composite trapezoidal rule for 2^k panels I [ k , 0 ] = trapezcomp ( f , a , b , 2 ** k ) # Romberg recursive formula for j in range ( 0 , k ): I [ k , j + 1 ] = ( 4 ** ( j + 1 ) * I [ k , j ] - I [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( I [ k , 0 : k + 1 ]) # display intermediate results return I if __name__ == '__main__' : def func ( x ): return np . sin ( x ) p_rows = 4 I = romberg ( func , 0 , np . pi / 2 , p_rows ) solution = I [ p_rows - 1 , p_rows - 1 ] print ( solution ) # 1.00000000814 [ 0.78539816 ] [ 0.94805945 1.00227988 ] [ 0.9871158 1.00013458 0.99999157 ] [ 0.99678517 1.0000083 0.99999988 1.00000001 ] 1.0000000081440203 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"integrasi numerik"},{"location":"Integrasi Numerik/#integrasi-numerik","text":"","title":"Integrasi Numerik"},{"location":"Integrasi Numerik/#metode-rumberg","text":"Metode integrasi Romberg didasarkan pada perluasan ekstrapolasi Richardson untuk memperoleh nilai integrasi yang semakin baik. Sebagai catatan, setiap penerapan ekstrapolasi Richardson akan menaikkan order galat pada hasil solusinya sebesar dua: $O( h 2N ) \u2192 O(h 2 N+2 O( h ) \u2192 O(h )$. Misalnya,bila I(h) dan I(2h) dihitung dengan kaidah trapesium yang berorde galat O(h 2), maka ekstrapolasi Richardson menghaslkan kaidah Simpson 1/3 yang berorde O(h 4). Selanjutnya, bila I(h) dan I(2h) dihitung dengan kaidah Simpson 1/3, ekstrapolasi Richardson menghaslkan kaidah Boole yang berorde O(h 6). Tinjau kembali persamaan ekstrapolasi Richardson: $$ J = I(h)+{1(h)-I(2h)\\over(2^q -1)} $$ misalkan I adalah nilai integrasi yang di nyatakan sebagai I = Ak + Ch2 + Dh4 + Eh6 + ... yang dalam hal ini h=(b-a)/n dan ak = perkiraan nilai integrasi dengan kaidah trapesium dan jumlah pias $n = 2^k$ Gunakan A0, A1,...Ak pada persamaan ekstrapolasi Richardson untuk mendapatkan runtunan B1, B2, ...,Bk , yaitu $$ B_k = A_k + {A_k -A_k{_-1}\\over 2^2-1} $$ Jadi, nilai I (yang lebih baik) sekarang adalah I = Bk + D'h4 + E'h6 +\u2026 dengan orde galat Bk adalah O(h4). Selanjutnya, gunakan B1, B2 ,.., Bk pada persamaan ekstrapolasi Richardson untuk mendapatkan runtunan C2, C3,..., Ck, yaitu $$ C_k = B_K + {B_k - B_k{_-1}\\over 2^4-1} $$ Jadi, nilai I (yang lebih baik) sekarang adalah I = Ck + E \" h6 + ... dengan orde galat Ck adalah O(h6). Selanjutnya, gunakan C2, C3 ,..., Ck pada persamaan ekstrapolasi Richardson untuk mendapatkan runtunan D3 , D4 , ... , Dk , yaitu $$ D_k = C_k +{ C_k-C_k{_-1}\\over 2^6-1} $$ Jadi, nilai I (yang lebih baik) sekarang adalah I = Dk + E \"' h8 + ... dengan orde galat Dk adalah O(h8). Demikian seterusnya. Dari runtunan tersebut, diperoleh tabel yang dinamakan tabel Romberg seperti berikut ini","title":"metode rumberg"},{"location":"Integrasi Numerik/#listing-program-rumberg-in-python","text":"import numpy as np def trapezcomp ( f , a , b , n ): h = ( b - a ) / n x = a In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 def romberg ( f , a , b , p ): I = np . zeros (( p , p )) for k in range ( 0 , p ): # Composite trapezoidal rule for 2^k panels I [ k , 0 ] = trapezcomp ( f , a , b , 2 ** k ) # Romberg recursive formula for j in range ( 0 , k ): I [ k , j + 1 ] = ( 4 ** ( j + 1 ) * I [ k , j ] - I [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( I [ k , 0 : k + 1 ]) # display intermediate results return I if __name__ == '__main__' : def func ( x ): return np . sin ( x ) p_rows = 4 I = romberg ( func , 0 , np . pi / 2 , p_rows ) solution = I [ p_rows - 1 , p_rows - 1 ] print ( solution ) # 1.00000000814 [ 0.78539816 ] [ 0.94805945 1.00227988 ] [ 0.9871158 1.00013458 0.99999157 ] [ 0.99678517 1.0000083 0.99999988 1.00000001 ] 1.0000000081440203 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"listing program rumberg in python"},{"location":"MISSING VELUES/","text":"jarak \u00b6 Menghitung jarak tipe numerik \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya Minkowski Distance $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Manhattan distance $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ Euclidean distance Average Distance $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ Weighted euclidean distance $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ Chord distance $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ dimana $$ L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum { i = 1 }^{ n }x_{i}^{2}} $$ ##### Menghitung Jarak Ordinal Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. Kategori-kategori ini disusun dalam peringkat. Yaitu, rentang atribut numerik dapat dipetakan ke atribut ordinal ff yang memiliki MfMf state. Misalnya, kisaran suhu atribut skala-skala (dalam Celcius)dapat diatur ke dalam status berikut: \u221230 hingga \u221210, \u221210 hingga 10, 10 hingga 30, masing-masing mewakili kategori suhu dingin, suhu sedang, dan suhu hangat. MM adalah jumlah keadaan yang dapat dilakukan oleh atribut ordinalmemiliki. State ini menentukan peringkat 1,...,Mf rumus $$ z _ { i f } = \\frac { r _ { i f } - 1 } { M _ { f } - 1 } $$ ##### Menghitung jarak Binary Mari kita lihat similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d722\u00d72 di mana qq adalah jumlah atribut yang sama dengan 1 untuk kedua objek ii dan jj, rr adalah jumlah atribut yang sama dengan 1 untuk objek ii tetapi 0 untuk objek jj, ss adalah jumlah atribut yang sama dengan 0 untuk objek ii tetapi 1 untuk objek jj, dan tt adalah jumlah atribut yang sama dengan 0 untuk kedua objek ii dan jj. Jumlah total atribut adalah pp, di mana p=q+r+s+t $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ berikut menghitung jarak dengan python ~~~py import pandas as pd import math as mt from sklearn.preprocessing import LabelEncoder data = pd.read_csv('jarak.csv', sep=';') df = pd.DataFrame(data) df.style.hide_index() ~~~ nama jesnis kelamin ipk p ortu prestasi imam l 3.8 3000000 internasional suci p 3.5 9000000 nasional rizky l 3.3 4000000 regional ```py X = data.iloc[:,:].values labelEncode_X = LabelEncoder() X[:,1] = labelEncode_X.fit_transform(X[:,1]) def Zscore(x,mean,std): top = x - mean if top==0: return top else: return round(top / std, 2) #menghitung jarak tipe numerikal def euclidianDistance(x,y): dis = 0 for i in range(len(x)): dis += (x[i] - y[i]) ** 2 return round(mt.sqrt(dis),2) def normalisasi(num, col_x): return Zscore(num, pd.Series(data[col_x].values).mean(), pd.Series(data[col_x].values).std()) #Menghitung Jarak tipe categorikal def distanceNom(x,y): p = len(x) or len(y) m = 0 for i in range(len(x)): if x[i][0] == y[i][0]: m +=1 return (p - m) / p #Menghitung Jarak tipe ordinal #inisialisasi x = {'Internasional':3,'Nasional':2,'Regional':1} def normalizedOrd(y): i_max = 0 for i in x: if x[i] > i_max: i_max = x[i] if y[0] == i: i_val = x[i] return (i_val - 1) / (i_max - 1) #Menghitung jarak tipe binary def distanceSimetris(x,y): q=r=s=t=0 for i in range(len(x)): if x[i]==1 and y[i]==1: q+=1 elif x[i]==1 and y[i]==0: r+=1 elif x[i]==0 and y[i]==1: s+=1 elif x[i]==0 and y[i]==0: t+=1 return ((r+s)/(q+r+s+t)) d_x = { 0 : ['', 'Ali', 'Ani', 'Abi'], 1 : ['Ali', 0, '', ''], 2 : ['Ani', '', 0, ''], 3 : ['Abi', '', '', 0] } #ambil data numerikal imamNum = df.iloc[0, 2:4].values suciNum = df.iloc[1, 2:4].values rizkyNum = df.iloc[2, 2:4].values #normalisasi data numerikal imamNum = [normalisasi(aliNum[0], data.columns[2]), normalisasi(aliNum[1], data.columns[3])] suciNum = [normalisasi(aniNum[0], data.columns[2]), normalisasi(aniNum[1], data.columns[3])] suciNum = [normalisasi(abiNum[0], data.columns[2]), normalisasi(abiNum[1], data.columns[3])] d_x[1][2] = euclidianDistance(aniNum,aliNum) d_x[1][3] = euclidianDistance(abiNum,aliNum) d_x[2][3] = euclidianDistance(abiNum,aniNum) d_x = pd.DataFrame(d_x) d_x.style.hide_index() ``` 0 1 2 3 imam suci rizky imam 0 suci 2.83 0 rizky 1.41 1.41 0 #ambil data binary imamBin = X [ 0 , 1 : 2 ] suciBin = X [ 1 , 1 : 2 ] rizkyBin = X [ 2 , 1 : 2 ] d_x [ 1 ][ 2 ] = distanceSimetris ( suciBin , imamBin ) d_x [ 1 ][ 3 ] = distanceSimetris ( rizkyBin , imamBin ) d_x [ 2 ][ 3 ] = distanceSimetris ( rizkyBin , suciBin ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () 0 1 2 3 imam suci rizky imam 0 suci 1 0 rizky 0 1 0 #ambil data ordinal aliOrd = [ df . iloc [ 0 , 5 : 6 ] . values ] aniOrd = [ df . iloc [ 1 , 5 : 6 ] . values ] abiOrd = [ df . iloc [ 2 , 5 : 6 ] . values ] d_x [ 1 ][ 2 ] = euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () 0 1 2 3 imam suci rizky imam 0 suci 1 0 rizky 0.5 0.5 0 #ambil data ordinal aliOrd = [ df . iloc [ 0 , 5 : 6 ] . values ] aniOrd = [ df . iloc [ 1 , 5 : 6 ] . values ] abiOrd = [ df . iloc [ 2 , 5 : 6 ] . values ] d_x [ 1 ][ 2 ] = euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () 0 1 2 3 imam suci imam imam 0 suci 5.83 0 rizky 2.91 3.91 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"jarak"},{"location":"MISSING VELUES/#jarak","text":"","title":"jarak"},{"location":"MISSING VELUES/#menghitung-jarak-tipe-numerik","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya Minkowski Distance $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Manhattan distance $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ Euclidean distance Average Distance $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ Weighted euclidean distance $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ Chord distance $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ dimana $$ L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum { i = 1 }^{ n }x_{i}^{2}} $$ ##### Menghitung Jarak Ordinal Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. Kategori-kategori ini disusun dalam peringkat. Yaitu, rentang atribut numerik dapat dipetakan ke atribut ordinal ff yang memiliki MfMf state. Misalnya, kisaran suhu atribut skala-skala (dalam Celcius)dapat diatur ke dalam status berikut: \u221230 hingga \u221210, \u221210 hingga 10, 10 hingga 30, masing-masing mewakili kategori suhu dingin, suhu sedang, dan suhu hangat. MM adalah jumlah keadaan yang dapat dilakukan oleh atribut ordinalmemiliki. State ini menentukan peringkat 1,...,Mf rumus $$ z _ { i f } = \\frac { r _ { i f } - 1 } { M _ { f } - 1 } $$ ##### Menghitung jarak Binary Mari kita lihat similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d722\u00d72 di mana qq adalah jumlah atribut yang sama dengan 1 untuk kedua objek ii dan jj, rr adalah jumlah atribut yang sama dengan 1 untuk objek ii tetapi 0 untuk objek jj, ss adalah jumlah atribut yang sama dengan 0 untuk objek ii tetapi 1 untuk objek jj, dan tt adalah jumlah atribut yang sama dengan 0 untuk kedua objek ii dan jj. Jumlah total atribut adalah pp, di mana p=q+r+s+t $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ berikut menghitung jarak dengan python ~~~py import pandas as pd import math as mt from sklearn.preprocessing import LabelEncoder data = pd.read_csv('jarak.csv', sep=';') df = pd.DataFrame(data) df.style.hide_index() ~~~ nama jesnis kelamin ipk p ortu prestasi imam l 3.8 3000000 internasional suci p 3.5 9000000 nasional rizky l 3.3 4000000 regional ```py X = data.iloc[:,:].values labelEncode_X = LabelEncoder() X[:,1] = labelEncode_X.fit_transform(X[:,1]) def Zscore(x,mean,std): top = x - mean if top==0: return top else: return round(top / std, 2) #menghitung jarak tipe numerikal def euclidianDistance(x,y): dis = 0 for i in range(len(x)): dis += (x[i] - y[i]) ** 2 return round(mt.sqrt(dis),2) def normalisasi(num, col_x): return Zscore(num, pd.Series(data[col_x].values).mean(), pd.Series(data[col_x].values).std()) #Menghitung Jarak tipe categorikal def distanceNom(x,y): p = len(x) or len(y) m = 0 for i in range(len(x)): if x[i][0] == y[i][0]: m +=1 return (p - m) / p #Menghitung Jarak tipe ordinal #inisialisasi x = {'Internasional':3,'Nasional':2,'Regional':1} def normalizedOrd(y): i_max = 0 for i in x: if x[i] > i_max: i_max = x[i] if y[0] == i: i_val = x[i] return (i_val - 1) / (i_max - 1) #Menghitung jarak tipe binary def distanceSimetris(x,y): q=r=s=t=0 for i in range(len(x)): if x[i]==1 and y[i]==1: q+=1 elif x[i]==1 and y[i]==0: r+=1 elif x[i]==0 and y[i]==1: s+=1 elif x[i]==0 and y[i]==0: t+=1 return ((r+s)/(q+r+s+t)) d_x = { 0 : ['', 'Ali', 'Ani', 'Abi'], 1 : ['Ali', 0, '', ''], 2 : ['Ani', '', 0, ''], 3 : ['Abi', '', '', 0] } #ambil data numerikal imamNum = df.iloc[0, 2:4].values suciNum = df.iloc[1, 2:4].values rizkyNum = df.iloc[2, 2:4].values #normalisasi data numerikal imamNum = [normalisasi(aliNum[0], data.columns[2]), normalisasi(aliNum[1], data.columns[3])] suciNum = [normalisasi(aniNum[0], data.columns[2]), normalisasi(aniNum[1], data.columns[3])] suciNum = [normalisasi(abiNum[0], data.columns[2]), normalisasi(abiNum[1], data.columns[3])] d_x[1][2] = euclidianDistance(aniNum,aliNum) d_x[1][3] = euclidianDistance(abiNum,aliNum) d_x[2][3] = euclidianDistance(abiNum,aniNum) d_x = pd.DataFrame(d_x) d_x.style.hide_index() ``` 0 1 2 3 imam suci rizky imam 0 suci 2.83 0 rizky 1.41 1.41 0 #ambil data binary imamBin = X [ 0 , 1 : 2 ] suciBin = X [ 1 , 1 : 2 ] rizkyBin = X [ 2 , 1 : 2 ] d_x [ 1 ][ 2 ] = distanceSimetris ( suciBin , imamBin ) d_x [ 1 ][ 3 ] = distanceSimetris ( rizkyBin , imamBin ) d_x [ 2 ][ 3 ] = distanceSimetris ( rizkyBin , suciBin ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () 0 1 2 3 imam suci rizky imam 0 suci 1 0 rizky 0 1 0 #ambil data ordinal aliOrd = [ df . iloc [ 0 , 5 : 6 ] . values ] aniOrd = [ df . iloc [ 1 , 5 : 6 ] . values ] abiOrd = [ df . iloc [ 2 , 5 : 6 ] . values ] d_x [ 1 ][ 2 ] = euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () 0 1 2 3 imam suci rizky imam 0 suci 1 0 rizky 0.5 0.5 0 #ambil data ordinal aliOrd = [ df . iloc [ 0 , 5 : 6 ] . values ] aniOrd = [ df . iloc [ 1 , 5 : 6 ] . values ] abiOrd = [ df . iloc [ 2 , 5 : 6 ] . values ] d_x [ 1 ][ 2 ] = euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () 0 1 2 3 imam suci imam imam 0 suci 5.83 0 rizky 2.91 3.91 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Menghitung jarak tipe numerik"},{"location":"Monte Carlo/","text":"Metode dan Simulasi Monte Carlo \u00b6 Metode Monte Carlo \u00b6 Metode Monte Carlo adalah algoritma kom put asi untuk mensimulasikan berbagai perilaku sistem fisika dan matematika. Penggunaan klasik metode ini adalah untuk mengevaluasi integral definit, terutama integral multidimensi dengan syarat dan batasan yang rumit Melihat dari cara kerjanya metode Monte Carlo merupakan metode yang memberikan segala kemungkinan nilai dari suatu variabel. Metode Monte Carlo merupakan metode yang memanfaatkan strong law of large number dalam melakukan perhitungan, artinya semakin banyak variabel acak yang digunakan akan semakin baik pula pendekatan nilai eksaknya Algoritma dan contoh metode monte carlo \u00b6 Probabilitas pelemparan coin Ganda Dari teori peluang akan muncul: MM \u00ce \u00bc MB atau BM \u00ce \u00bd BB \u00ce \u00bc Dengan metode Monte Carlo dapatkan tingkat ketelitian sampai 0.01 untuk menyelesaikan kasus tersebut\u2026. Untuk mendapatkan ketelitian sampai 0,01 maka harus dilakukan pelemparan sebanyak 1000 (N_total) kali. Dari hasil pelemparan catat keluarnya angka-angka: P(MM) = N(MM)/N_total P(MB) = N(MB)/N_total P(BB) = N(BB)/N_total Algorithma \u00b6 Bangkitkan nilai 0/1 sebanyak 1000 kali (N=1000) dengan cara: n1 =(int)rand()%2 dan n2 =(int)rand()%2 Klasifikasi Jika n1=0 dan n2=0, maka MM=MM+1 Jika n1=0 dan n2=1 atau n1=1 dan n2=0 maka MB=MB+1 Jika n1=1 dan n2=1, maka BB=BB+1 Hitung probabilitas MM dengan cara N(MM)/N dan probabilitas untuk nilai MB serta BB 2.Menghitung Nilai Integral dengan monte carlo Luas area dicari = yang berwarna atau daerah dibawah garis fungsi f(x) = 2x Dengan dasar pemikiran tersebut diperoleh suatu perbandingan: BIla kita melakukan pelemparan coin sebanyak N kali, dan coin jatuh di bawah garis f(x) =2x sebanyak M kali. Maka: Algoritma \u00b6 tugas programing \u00b6 implemenasi metode carlo dalam python \u00b6 from scipy import random import numpy as np import matplotlib.pyplot as plt a = 0 b = 2 N = 2500 def func ( x ): return ( 4 - x ** 2 ) ** 0.5 area = [] for i in range ( N ): xrand = np . zeros ( N ) for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) integral = 0.0 for i in range ( N ): integral += func ( xrand [ i ]) jawab = ( b - a ) / float ( N ) * integral area . append ( jawab ) plt . title ( \"Hasil phi\" ) plt . hist ( area , bins = 30 , ec = 'black' ) plt . xlabel ( \"Area\" ) plt . show () hasil running \u00b6 from scipy import random import numpy as np a = - 1 b = 1 N = 100 xrand = np . zeros ( N ) yrand = np . zeros ( N ) zrand = np . zeros ( N ) integral = 0.0 for i in range ( 4 ): for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) for i in range ( len ( yrand )): yrand [ i ] = random . uniform ( a , b ) for i in range ( len ( zrand )): zrand [ i ] = random . uniform ( a , b ) def func ( x , y , z ): return ( x ** 2 ) + ( y ** 2 ) + ( z ** 2 ) for i in range ( N ): integral += func ( xrand [ i ], yrand [ i ], zrand [ i ]) jawab = ( b - a ) / float ( N ) * integral print ( \"jawab: \" , jawab ) hasil running \u00b6 jawab : 7.941487167529855","title":"Metode dan Simulasi Monte Carlo"},{"location":"Monte Carlo/#metode-dan-simulasi-monte-carlo","text":"","title":"Metode dan Simulasi Monte Carlo"},{"location":"Monte Carlo/#metode-monte-carlo","text":"Metode Monte Carlo adalah algoritma kom put asi untuk mensimulasikan berbagai perilaku sistem fisika dan matematika. Penggunaan klasik metode ini adalah untuk mengevaluasi integral definit, terutama integral multidimensi dengan syarat dan batasan yang rumit Melihat dari cara kerjanya metode Monte Carlo merupakan metode yang memberikan segala kemungkinan nilai dari suatu variabel. Metode Monte Carlo merupakan metode yang memanfaatkan strong law of large number dalam melakukan perhitungan, artinya semakin banyak variabel acak yang digunakan akan semakin baik pula pendekatan nilai eksaknya","title":"Metode  Monte Carlo"},{"location":"Monte Carlo/#algoritma-dan-contoh-metode-monte-carlo","text":"Probabilitas pelemparan coin Ganda Dari teori peluang akan muncul: MM \u00ce \u00bc MB atau BM \u00ce \u00bd BB \u00ce \u00bc Dengan metode Monte Carlo dapatkan tingkat ketelitian sampai 0.01 untuk menyelesaikan kasus tersebut\u2026. Untuk mendapatkan ketelitian sampai 0,01 maka harus dilakukan pelemparan sebanyak 1000 (N_total) kali. Dari hasil pelemparan catat keluarnya angka-angka: P(MM) = N(MM)/N_total P(MB) = N(MB)/N_total P(BB) = N(BB)/N_total","title":"Algoritma dan contoh metode monte carlo"},{"location":"Monte Carlo/#algorithma","text":"Bangkitkan nilai 0/1 sebanyak 1000 kali (N=1000) dengan cara: n1 =(int)rand()%2 dan n2 =(int)rand()%2 Klasifikasi Jika n1=0 dan n2=0, maka MM=MM+1 Jika n1=0 dan n2=1 atau n1=1 dan n2=0 maka MB=MB+1 Jika n1=1 dan n2=1, maka BB=BB+1 Hitung probabilitas MM dengan cara N(MM)/N dan probabilitas untuk nilai MB serta BB 2.Menghitung Nilai Integral dengan monte carlo Luas area dicari = yang berwarna atau daerah dibawah garis fungsi f(x) = 2x Dengan dasar pemikiran tersebut diperoleh suatu perbandingan: BIla kita melakukan pelemparan coin sebanyak N kali, dan coin jatuh di bawah garis f(x) =2x sebanyak M kali. Maka:","title":"Algorithma"},{"location":"Monte Carlo/#algoritma","text":"","title":"Algoritma"},{"location":"Monte Carlo/#tugas-programing","text":"","title":"tugas programing"},{"location":"Monte Carlo/#implemenasi-metode-carlo-dalam-python","text":"from scipy import random import numpy as np import matplotlib.pyplot as plt a = 0 b = 2 N = 2500 def func ( x ): return ( 4 - x ** 2 ) ** 0.5 area = [] for i in range ( N ): xrand = np . zeros ( N ) for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) integral = 0.0 for i in range ( N ): integral += func ( xrand [ i ]) jawab = ( b - a ) / float ( N ) * integral area . append ( jawab ) plt . title ( \"Hasil phi\" ) plt . hist ( area , bins = 30 , ec = 'black' ) plt . xlabel ( \"Area\" ) plt . show ()","title":"implemenasi metode carlo dalam python"},{"location":"Monte Carlo/#hasil-running","text":"from scipy import random import numpy as np a = - 1 b = 1 N = 100 xrand = np . zeros ( N ) yrand = np . zeros ( N ) zrand = np . zeros ( N ) integral = 0.0 for i in range ( 4 ): for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) for i in range ( len ( yrand )): yrand [ i ] = random . uniform ( a , b ) for i in range ( len ( zrand )): zrand [ i ] = random . uniform ( a , b ) def func ( x , y , z ): return ( x ** 2 ) + ( y ** 2 ) + ( z ** 2 ) for i in range ( N ): integral += func ( xrand [ i ], yrand [ i ], zrand [ i ]) jawab = ( b - a ) / float ( N ) * integral print ( \"jawab: \" , jawab )","title":"hasil running"},{"location":"Monte Carlo/#hasil-running_1","text":"jawab : 7.941487167529855","title":"hasil running"},{"location":"Numerical Solution/","text":"Numerical Solution of Algebraic and Transcendental Equation \u00b6 Sistem persaman aljabar dapat diuraikan seperti dibawah ini Persamaan transcendental : sin, cos, tan, Persamaan polynomial : a0 + a1x + a2x2 \u2026\u2026. + anxn + \u2026\u2026 Penyelesaian persamaan non linier \u00b6 Metode Tertutup Mencari akar pada range [a,b] tertentu Dalam range[a,b] dipastikan terdapat satu akar Hasil selalu konvergen \u2192 disebut juga metode konvergen Contohnya Metode Tabel ,Metode Biseksi,Metode Regula Falsi Metode Terbuka Diperlukan tebakan awal xn dipakai untuk menghitung xn+1 Hasil dapat konvergen atau divergen Contohnya Metode Iterasi Sederhana, Metode Newton-Raphson, Metode Secant. method Bisection Metode biseksi ini membagi range menjadi 2 bagian, dari dua bagian ini dipilih bagian mana yang mengandung akar sedangkan bagian yang tidak mengandung akar akan dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh suatu akar persamaan langkah langkah Tentukan batas bawah (a) dan batas atas (b). Kemudian dihitung nilai tengah : $$ c = {(a+b)\\over 2} $$ Dari nilai c ini perlu dilakukan pengecekan keberadaan akar. Secara matematik, suatu range terdapat akar persamaan bila f(a) dan f(b) berlawanan tanda atau dituliskan : $$ f(a).f(b) <0 $$ Setelah diketahui di bagian mana terdapat akar, maka batas bawah dan batas atas diperbarui sesuai dengan range dari bagian yang mempunyai akar algoritma metode bisection 1.Definisikan fungsi f(x) yang akan dicari akarnya 2.Tentukan nilai a dan b 3.Tentukan toleransi e dan iterasi maksimum N 4.Hitung f(a) dan f(b) 5.Jika f(a).f(b)>0 maka proses dihentikan karena tidak ada akar, bila tidak maka dilanjutkan 6.Hitung x = (a+b)/2 7.Hitung f(x) 8.Bila f(x).f(a)<0 maka b = x dan f(b)=f(x), bila tidak maka a=x dan f(a)=f(x) 9.Jika |b-a|< e atau iterasi > iterasi maks maka proses dihentikan dan didapatkan akar x, bila tidak, ulangi langkah 6 implementasi metode bisection dalam python \u00b6 def bisection ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Bisection method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = ( a_n + b_n ) / 2 f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Bisection method fails.\" ) return None return ( a_n + b_n ) / 2 f = lambda x : x ** 2 - 5 * x + 6 approx_phi = bisection ( f , 1 , 2.3 , 25 ) print ( approx_phi ) 1.9999999985098835 methot Regula Falsi 1.Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. 2.Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. 3.Dikenal dengan metode False Position 4.Metode ini juga merupakan penyempurna dari metode bisection algoritma method regula falsi Definisikan fungsi f(x) Tentukan batas bawah (a) dan batas atas (b) Tentukan toleransi error e Hitung f(a) dan f(b) Untuk iterasi 1 s/d n > e : $$ c= {(f(b).a -f(a).b)\\over (f(b)-f(a))} $$ Hitung f(c)=f(x) \u200b Hitung error = |f(c)| \u200b Jika f(c).f(a)<0 maka nilai a tetap ,jika tidak maka a=c dan f(a)=f(c) Akar persamaanya = c implementasi method regula falsi dalam python \u00b6 error = 0.01 a = 0 b = 2.1 def f ( x ): return x ** 2 - 5 * x + 6 def regulasi_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x if f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regulasi_falsi ( a , b ) x = 2.000000000174259 Metode Newton Raphson Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position Metode ini juga merupakan penyempurna dari metode bisection Prinsip Metode Newton Raphson Metode Newton-Raphson adalah metode pencarian akar suatu fungsi f(x) dengan pendekatan satu titik, dimana fungsi f(x) mempunyai turunan. Metode ini dianggap lebih mudah dari Metode Bagi-Dua (Bisection Method) karena metode ini menggunakan pendekatan satu titik sebagai titik awal. prosedur Menentukan x0 sebagai titik awal. Menarik garis lurus (misal garis P) yang menyinggung titik f(x0). Hal ini berakibat garis P memotong sumbu-x di titik x1. Ulangi langkah sebelumnya tapi sekarang x1 dianggap sebagai titik awalnya. Dari mengulang langkah-langkah sebelumnya akan mendapatkan x1,x2,x3,...,,xn dengan xn yang diperoleh adalah bilangan riil yang merupakan akar atau mendekati akar yang sebenarnya algoritma implementasi Metode Newton Raphson python \u00b6 def newton ( f , Df , x0 , epsilon , max_iter ): xn = x0 for n in range ( 0 , max_iter ): fxn = f ( xn ) if abs ( fxn ) < epsilon : print ( 'Found solution after' , n , 'iterations.' ) return xn Dfxn = Df ( xn ) if Dfxn == 0 : print ( 'Zero derivative. No solution found.' ) return None xn = xn - fxn / Dfxn print ( 'Exceeded maximum iterations. No solution found.' ) return None p = lambda x : x ** 2 - 5 * x + 6 Dp = lambda x : 2 * x - 5 approx = newton ( p , Dp , 1 , 1e-3 , 10 ) print ( approx ) Found solution after 4 iterations . 1.9999847409781035 Metode Secant \u25a0Metode Newton Raphson memerlukan perhitungan turunan fungsi f\u2019(x). \u25a0Tidak semua fungsi mudah dicari turunannya terutama fungsi yang bentuknya rumit. \u25a0Turunan fungsi dapat dihilangkan dengan cara menggantinya dengan bentuk lain yang ekivalen \u25a0Modifikasi metode Newton Raphson dinamakan metode Secant. formula secant \u00b6 $$ y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ x = a - f(a)\\frac{b - a}{f(b) - f(a)} $$ algoritma method secant \u00b6 \u25a0 Definisikan f(x) \u25a0 Definisikan toleransi error e dan iterasi maksimum (n) \u25a0 Masukan dua nilai pendekatan awal yang diantaranya terdapat akar yaitu x_0 dan x_1 ,sebaiknya gunakan metode tabel untuk menjamin titik pendekatanya adalah titik pendekatan yang konvergensinya pada akar persamaan yang diharapkan. \u25a0 Hitung f(x_0 ) dan fx_1 sebagai y_0 dan y_1 \u25a0 Untuk iterasi 1 s/d n x_(i+1)= x_i-(f(xi)(x_i \u3016-x\u3017 (i-1)))/(y_i - y (i-1) ) hitung y_(i+1)=\u3016f(x\u3017_(i+1)) Akar persamaan adalah nilai x yang terakhir implementasi method secant pada python \u00b6 def secant ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Secant method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Secant method fails.\" ) return None return a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) p = lambda x : x ** 2 - 5 * x + 6 approx = secant ( p , 1 , 2.4 , 20 ) print ( approx ) 2.0000003178913373 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Numerical Solution"},{"location":"Numerical Solution/#numerical-solution-of-algebraic-and-transcendental-equation","text":"Sistem persaman aljabar dapat diuraikan seperti dibawah ini Persamaan transcendental : sin, cos, tan, Persamaan polynomial : a0 + a1x + a2x2 \u2026\u2026. + anxn + \u2026\u2026","title":"Numerical Solution of Algebraic and Transcendental Equation"},{"location":"Numerical Solution/#penyelesaian-persamaan-non-linier","text":"Metode Tertutup Mencari akar pada range [a,b] tertentu Dalam range[a,b] dipastikan terdapat satu akar Hasil selalu konvergen \u2192 disebut juga metode konvergen Contohnya Metode Tabel ,Metode Biseksi,Metode Regula Falsi Metode Terbuka Diperlukan tebakan awal xn dipakai untuk menghitung xn+1 Hasil dapat konvergen atau divergen Contohnya Metode Iterasi Sederhana, Metode Newton-Raphson, Metode Secant. method Bisection Metode biseksi ini membagi range menjadi 2 bagian, dari dua bagian ini dipilih bagian mana yang mengandung akar sedangkan bagian yang tidak mengandung akar akan dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh suatu akar persamaan langkah langkah Tentukan batas bawah (a) dan batas atas (b). Kemudian dihitung nilai tengah : $$ c = {(a+b)\\over 2} $$ Dari nilai c ini perlu dilakukan pengecekan keberadaan akar. Secara matematik, suatu range terdapat akar persamaan bila f(a) dan f(b) berlawanan tanda atau dituliskan : $$ f(a).f(b) <0 $$ Setelah diketahui di bagian mana terdapat akar, maka batas bawah dan batas atas diperbarui sesuai dengan range dari bagian yang mempunyai akar algoritma metode bisection 1.Definisikan fungsi f(x) yang akan dicari akarnya 2.Tentukan nilai a dan b 3.Tentukan toleransi e dan iterasi maksimum N 4.Hitung f(a) dan f(b) 5.Jika f(a).f(b)>0 maka proses dihentikan karena tidak ada akar, bila tidak maka dilanjutkan 6.Hitung x = (a+b)/2 7.Hitung f(x) 8.Bila f(x).f(a)<0 maka b = x dan f(b)=f(x), bila tidak maka a=x dan f(a)=f(x) 9.Jika |b-a|< e atau iterasi > iterasi maks maka proses dihentikan dan didapatkan akar x, bila tidak, ulangi langkah 6","title":"Penyelesaian persamaan non linier"},{"location":"Numerical Solution/#implementasi-metode-bisection-dalam-python","text":"def bisection ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Bisection method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = ( a_n + b_n ) / 2 f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Bisection method fails.\" ) return None return ( a_n + b_n ) / 2 f = lambda x : x ** 2 - 5 * x + 6 approx_phi = bisection ( f , 1 , 2.3 , 25 ) print ( approx_phi ) 1.9999999985098835 methot Regula Falsi 1.Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. 2.Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. 3.Dikenal dengan metode False Position 4.Metode ini juga merupakan penyempurna dari metode bisection algoritma method regula falsi Definisikan fungsi f(x) Tentukan batas bawah (a) dan batas atas (b) Tentukan toleransi error e Hitung f(a) dan f(b) Untuk iterasi 1 s/d n > e : $$ c= {(f(b).a -f(a).b)\\over (f(b)-f(a))} $$ Hitung f(c)=f(x) \u200b Hitung error = |f(c)| \u200b Jika f(c).f(a)<0 maka nilai a tetap ,jika tidak maka a=c dan f(a)=f(c) Akar persamaanya = c","title":"implementasi metode bisection dalam python"},{"location":"Numerical Solution/#implementasi-method-regula-falsi-dalam-python","text":"error = 0.01 a = 0 b = 2.1 def f ( x ): return x ** 2 - 5 * x + 6 def regulasi_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x if f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regulasi_falsi ( a , b ) x = 2.000000000174259 Metode Newton Raphson Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position Metode ini juga merupakan penyempurna dari metode bisection Prinsip Metode Newton Raphson Metode Newton-Raphson adalah metode pencarian akar suatu fungsi f(x) dengan pendekatan satu titik, dimana fungsi f(x) mempunyai turunan. Metode ini dianggap lebih mudah dari Metode Bagi-Dua (Bisection Method) karena metode ini menggunakan pendekatan satu titik sebagai titik awal. prosedur Menentukan x0 sebagai titik awal. Menarik garis lurus (misal garis P) yang menyinggung titik f(x0). Hal ini berakibat garis P memotong sumbu-x di titik x1. Ulangi langkah sebelumnya tapi sekarang x1 dianggap sebagai titik awalnya. Dari mengulang langkah-langkah sebelumnya akan mendapatkan x1,x2,x3,...,,xn dengan xn yang diperoleh adalah bilangan riil yang merupakan akar atau mendekati akar yang sebenarnya algoritma","title":"implementasi method regula falsi dalam python"},{"location":"Numerical Solution/#implementasi-metode-newton-raphson-python","text":"def newton ( f , Df , x0 , epsilon , max_iter ): xn = x0 for n in range ( 0 , max_iter ): fxn = f ( xn ) if abs ( fxn ) < epsilon : print ( 'Found solution after' , n , 'iterations.' ) return xn Dfxn = Df ( xn ) if Dfxn == 0 : print ( 'Zero derivative. No solution found.' ) return None xn = xn - fxn / Dfxn print ( 'Exceeded maximum iterations. No solution found.' ) return None p = lambda x : x ** 2 - 5 * x + 6 Dp = lambda x : 2 * x - 5 approx = newton ( p , Dp , 1 , 1e-3 , 10 ) print ( approx ) Found solution after 4 iterations . 1.9999847409781035 Metode Secant \u25a0Metode Newton Raphson memerlukan perhitungan turunan fungsi f\u2019(x). \u25a0Tidak semua fungsi mudah dicari turunannya terutama fungsi yang bentuknya rumit. \u25a0Turunan fungsi dapat dihilangkan dengan cara menggantinya dengan bentuk lain yang ekivalen \u25a0Modifikasi metode Newton Raphson dinamakan metode Secant.","title":"implementasi Metode Newton Raphson python"},{"location":"Numerical Solution/#formula-secant","text":"$$ y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) $$ $$ x = a - f(a)\\frac{b - a}{f(b) - f(a)} $$","title":"formula secant"},{"location":"Numerical Solution/#algoritma-method-secant","text":"\u25a0 Definisikan f(x) \u25a0 Definisikan toleransi error e dan iterasi maksimum (n) \u25a0 Masukan dua nilai pendekatan awal yang diantaranya terdapat akar yaitu x_0 dan x_1 ,sebaiknya gunakan metode tabel untuk menjamin titik pendekatanya adalah titik pendekatan yang konvergensinya pada akar persamaan yang diharapkan. \u25a0 Hitung f(x_0 ) dan fx_1 sebagai y_0 dan y_1 \u25a0 Untuk iterasi 1 s/d n x_(i+1)= x_i-(f(xi)(x_i \u3016-x\u3017 (i-1)))/(y_i - y (i-1) ) hitung y_(i+1)=\u3016f(x\u3017_(i+1)) Akar persamaan adalah nilai x yang terakhir","title":"algoritma method secant"},{"location":"Numerical Solution/#implementasi-method-secant-pada-python","text":"def secant ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Secant method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Secant method fails.\" ) return None return a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) p = lambda x : x ** 2 - 5 * x + 6 approx = secant ( p , 1 , 2.4 , 20 ) print ( approx ) 2.0000003178913373 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"implementasi method secant pada python"},{"location":"Tugas3/","text":"Eliminasi Gauss Jordan \u00b6 \u200b Eliminasi Gauss adalah suatu metode untuk mengoperasikan nilai-nilai di dalam matriks sehingga menjadi matriks yang lebih sederhana lagi. Dengan melakukan operasi baris sehingga matriks tersebut menjadi matriks yang baris. Ini dapat digunakan sebagai salah satu metode penyelesaian persamaan linear dengan menggunakan matriks. Caranya dengan mengubah persamaan linear tersebut ke dalam matriks teraugmentasi dan mengoperasikannya. Setelah menjadi matriks baris, lakukan substitusi balik untuk mendapatkan nilai dari variabel-variabel tersebut. \u200b Metode Eliminasi Gauss Jordan merupakan pengembangan metode eliminasi gauss, hanya saja augmented matrik , pada sebelah kiri dirubah menjadi matrik diagonal. Algoritma Gauss Jordan \u00b6 \u00b6 Listing Program \u00b6 import numpy as np #Definisi Matrix A = [] B = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) A . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) B . append ( h ) Matrix = np . array ( A , float ) Hasil = np . array ( B , float ) n = len ( Matrix ) #Eliminasi Gauss for k in range ( 0 , n - 1 ): for i in range ( k + 1 , n ): if Matrix [ i , k ] != 0 : lam = Matrix [ i , k ] / Matrix [ k , k ] Matrix [ i , k : n ] = Matrix [ i , k : n ] - ( Matrix [ k , k : n ] * lam ) Hasil [ i ] = Hasil [ i ] - ( Hasil [ k ] * lam ) print ( \"Matrix A : \" , ' \\n ' , Matrix ) #Subtitution x = np . zeros ( n , float ) for m in range ( n - 1 , - 1 , - 1 ): x [ m ] = ( Hasil [ m ] - np . dot ( Matrix [ m , m + 1 : n ], x [ m + 1 : n ])) / Matrix [ m , m ] print ( 'Nilai X ' , m + 1 , '=' , x [ m ]) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Nilai: 1 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Nilai: 4 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Hasil: 12 Masukkan Hasil: 3 Masukkan Hasil: -4 Matrix A : [[ 2. -2. 5. ] [ 0. 6. -0.5 ] [ 0. 0. -7.25]] Nilai X 3 = 3.2413793103448274 Nilai X 2 = -0.2298850574712644 Nilai X 1 = -2.333333333333332 jadi panjang Matrix yang dibuat dalam Program Diatas adalah 3 variabel. |2 -2 5| |12| |1 5 2|=| 3 | |4 5 2| |-4| pivot yang dibentuk adalah a1.1,a2.2,dan a3.3 sehingga semua angka yang ada dibawah pivot akan dikonversikan menjadi nol sesuai hasil program dan hasil dari persamaan diatas menghasilkan x1=-2.333333333, x2=-0.22988505 dan x3=3.2413793 Eliminasi Gauss Jacobi \u00b6 Metode IterasiJacobi merupakan salah satu bidang analisis numerik yang digunakan untuk menyelesaikan permasalahan Persamaan Linier dan sering dijumpai dalam berbagai disiplin ilmu. Metode Iterasi Jacobi merupakan salah satu metode tak langsung, yaitu bermula dari suatu hampiran penyelesaian awal dan kemudian berusaha memperbaiki hampiran dalam tak berhingga namun langkah konvergen. Metode Iterasi Jacobi ini digunakan untuk menyelesaikan persamaan Linier berukuran besar dan proporsi koefisien nolnya besar. Metode ini ditemukan oleh Matematikawan yang berasal dari Jerman,Carl,Gustav,Jacobi. Penemuan ini diperkirakan pada tahun 1800-an. Listing Program \u00b6 from pprint import pprint from numpy import array , zeros , diag , diagflat , dot import numpy as np def jacobi ( A , b , N = 25 , x = None ): #Membuat iniial guess if x is None : x = zeros ( len ( A [ 0 ])) #Membuat vektor dari elemen matrix A D = diag ( A ) R = A - diagflat ( D ) #Iterasi for i in range ( N ): x = ( b - dot ( R , x )) / D return x Mat1 = [] Mat2 = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) Mat1 . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) Mat2 . append ( h ) A = array ( Mat1 , float ) b = array ( Mat2 , float ) x = len ( Mat1 ) guess = np . zeros ( x , float ) sol = jacobi ( A , b , N = 25 , x = guess ) print ( \"A:\" ) pprint ( A ) print ( \"b:\" ) pprint ( b ) print ( \"x:\" ) pprint ( sol ) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 3 Masukkan Nilai: 1 Masukkan Nilai: -1 Masukkan Nilai: 4 Masukkan Nilai: 7 Masukkan Nilai: -3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Hasil: 5 Masukkan Hasil: 20 Masukkan Hasil: 10 A: array([[ 3., 1., -1.], [ 4., 7., -3.], [ 2., -2., 5.]]) b: array([ 5., 20., 10.]) x: array([1.50602413, 3.13253016, 2.6506024 ]) Program Gauss Seidel \u00b6 Listing Program \u00b6 def seidel ( a , x , b ): #Mencari Panjang Matrix n = len ( a ) for j in range ( 0 , n ): d = b [ j ] #Menghitung xi, yi, zi for i in range ( 0 , n ): if ( j != i ): d -= a [ j ][ i ] * x [ i ] x [ j ] = d / a [ j ][ j ] #Solusi return x m = int ( input ( \"Masukkan Panjang Matrix: \" )) a = [] b = [] for k in range ( m ): mat1 = [] for i in range ( m ): l = float ( input ( \"Masukkan a\" + str ( k + 1 ) + \",\" + str ( i + 1 ) + \": \" )) mat1 . append ( l ) h = float ( input ( \"Masukkan Hasil: \" )) b . append ( h ) a . append ( mat1 ) n = 3 x = [ 0 , 0 , 0 ] print ( x ) for i in range ( 0 , 100 ): x = seidel ( a , x , b ) print ( x ) Output: Masukkan Panjang Matrix: 3 Masukkan a1,1: 4 Masukkan a1,2: -1 Masukkan a1,3: 1 Masukkan Hasil: 7 Masukkan a2,1: 4 Masukkan a2,2: -8 Masukkan a2,3: 1 Masukkan Hasil: -21 Masukkan a3,1: -2 Masukkan a3,2: 1 Masukkan a3,3: 5 Masukkan Hasil: 15 [0, 0, 0] [1.75, 3.5, 3.0] [1.875, 3.9375, 2.9625] [1.99375, 3.9921875, 2.9990625] [1.99828125, 3.9990234375, 2.9995078125] [1.99987890625, 3.9998779296875, 2.9999759765625003] [1.99997548828125, 3.9999847412109375, 2.999993247070312] [1.9999978735351562, 3.9999980926513667, 2.999999530883789] [1.9999996404418945, 3.9999997615814205, 2.9999999038604734] [1.9999999644302369, 3.9999999701976776, 2.9999999917325595] [1.9999999946162794, 3.9999999962747097, 2.99999999859157] [1.9999999994207849, 3.9999999995343387, 2.9999999998614464] [1.9999999999182232, 3.999999999941793, 2.999999999978931] [1.9999999999907154, 3.999999999992724, 2.9999999999977414] [1.9999999999987457, 3.9999999999990905, 2.9999999999996803] [1.9999999999998526, 3.9999999999998863, 2.9999999999999636] [1.9999999999999807, 3.999999999999986, 2.999999999999995] [1.9999999999999978, 3.9999999999999987, 2.9999999999999996] [1.9999999999999996, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] Dari soal diatas persamaan yang dipilih adalah 4x-y+z=7, 4x-8y+z=-21 dan -2x+y+5z=15. Iterasi yang digunakan sebanyak 100 iterasi sehingga dapat menghasilkan x=2,y=4 dan z=3. Sekian dan Terima Kasih","title":"persamman linier"},{"location":"Tugas3/#eliminasi-gauss-jordan","text":"\u200b Eliminasi Gauss adalah suatu metode untuk mengoperasikan nilai-nilai di dalam matriks sehingga menjadi matriks yang lebih sederhana lagi. Dengan melakukan operasi baris sehingga matriks tersebut menjadi matriks yang baris. Ini dapat digunakan sebagai salah satu metode penyelesaian persamaan linear dengan menggunakan matriks. Caranya dengan mengubah persamaan linear tersebut ke dalam matriks teraugmentasi dan mengoperasikannya. Setelah menjadi matriks baris, lakukan substitusi balik untuk mendapatkan nilai dari variabel-variabel tersebut. \u200b Metode Eliminasi Gauss Jordan merupakan pengembangan metode eliminasi gauss, hanya saja augmented matrik , pada sebelah kiri dirubah menjadi matrik diagonal.","title":"Eliminasi Gauss Jordan"},{"location":"Tugas3/#algoritma-gauss-jordan","text":"","title":"Algoritma Gauss Jordan"},{"location":"Tugas3/#listing-program","text":"import numpy as np #Definisi Matrix A = [] B = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) A . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) B . append ( h ) Matrix = np . array ( A , float ) Hasil = np . array ( B , float ) n = len ( Matrix ) #Eliminasi Gauss for k in range ( 0 , n - 1 ): for i in range ( k + 1 , n ): if Matrix [ i , k ] != 0 : lam = Matrix [ i , k ] / Matrix [ k , k ] Matrix [ i , k : n ] = Matrix [ i , k : n ] - ( Matrix [ k , k : n ] * lam ) Hasil [ i ] = Hasil [ i ] - ( Hasil [ k ] * lam ) print ( \"Matrix A : \" , ' \\n ' , Matrix ) #Subtitution x = np . zeros ( n , float ) for m in range ( n - 1 , - 1 , - 1 ): x [ m ] = ( Hasil [ m ] - np . dot ( Matrix [ m , m + 1 : n ], x [ m + 1 : n ])) / Matrix [ m , m ] print ( 'Nilai X ' , m + 1 , '=' , x [ m ]) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Nilai: 1 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Nilai: 4 Masukkan Nilai: 5 Masukkan Nilai: 2 Masukkan Hasil: 12 Masukkan Hasil: 3 Masukkan Hasil: -4 Matrix A : [[ 2. -2. 5. ] [ 0. 6. -0.5 ] [ 0. 0. -7.25]] Nilai X 3 = 3.2413793103448274 Nilai X 2 = -0.2298850574712644 Nilai X 1 = -2.333333333333332 jadi panjang Matrix yang dibuat dalam Program Diatas adalah 3 variabel. |2 -2 5| |12| |1 5 2|=| 3 | |4 5 2| |-4| pivot yang dibentuk adalah a1.1,a2.2,dan a3.3 sehingga semua angka yang ada dibawah pivot akan dikonversikan menjadi nol sesuai hasil program dan hasil dari persamaan diatas menghasilkan x1=-2.333333333, x2=-0.22988505 dan x3=3.2413793","title":"Listing Program"},{"location":"Tugas3/#eliminasi-gauss-jacobi","text":"Metode IterasiJacobi merupakan salah satu bidang analisis numerik yang digunakan untuk menyelesaikan permasalahan Persamaan Linier dan sering dijumpai dalam berbagai disiplin ilmu. Metode Iterasi Jacobi merupakan salah satu metode tak langsung, yaitu bermula dari suatu hampiran penyelesaian awal dan kemudian berusaha memperbaiki hampiran dalam tak berhingga namun langkah konvergen. Metode Iterasi Jacobi ini digunakan untuk menyelesaikan persamaan Linier berukuran besar dan proporsi koefisien nolnya besar. Metode ini ditemukan oleh Matematikawan yang berasal dari Jerman,Carl,Gustav,Jacobi. Penemuan ini diperkirakan pada tahun 1800-an.","title":"Eliminasi Gauss Jacobi"},{"location":"Tugas3/#listing-program_1","text":"from pprint import pprint from numpy import array , zeros , diag , diagflat , dot import numpy as np def jacobi ( A , b , N = 25 , x = None ): #Membuat iniial guess if x is None : x = zeros ( len ( A [ 0 ])) #Membuat vektor dari elemen matrix A D = diag ( A ) R = A - diagflat ( D ) #Iterasi for i in range ( N ): x = ( b - dot ( R , x )) / D return x Mat1 = [] Mat2 = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) Mat1 . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) Mat2 . append ( h ) A = array ( Mat1 , float ) b = array ( Mat2 , float ) x = len ( Mat1 ) guess = np . zeros ( x , float ) sol = jacobi ( A , b , N = 25 , x = guess ) print ( \"A:\" ) pprint ( A ) print ( \"b:\" ) pprint ( b ) print ( \"x:\" ) pprint ( sol ) Output: Masukkan ukuran Matrix: 3 Masukkan Nilai: 3 Masukkan Nilai: 1 Masukkan Nilai: -1 Masukkan Nilai: 4 Masukkan Nilai: 7 Masukkan Nilai: -3 Masukkan Nilai: 2 Masukkan Nilai: -2 Masukkan Nilai: 5 Masukkan Hasil: 5 Masukkan Hasil: 20 Masukkan Hasil: 10 A: array([[ 3., 1., -1.], [ 4., 7., -3.], [ 2., -2., 5.]]) b: array([ 5., 20., 10.]) x: array([1.50602413, 3.13253016, 2.6506024 ])","title":"Listing Program"},{"location":"Tugas3/#program-gauss-seidel","text":"","title":"Program Gauss Seidel"},{"location":"Tugas3/#listing-program_2","text":"def seidel ( a , x , b ): #Mencari Panjang Matrix n = len ( a ) for j in range ( 0 , n ): d = b [ j ] #Menghitung xi, yi, zi for i in range ( 0 , n ): if ( j != i ): d -= a [ j ][ i ] * x [ i ] x [ j ] = d / a [ j ][ j ] #Solusi return x m = int ( input ( \"Masukkan Panjang Matrix: \" )) a = [] b = [] for k in range ( m ): mat1 = [] for i in range ( m ): l = float ( input ( \"Masukkan a\" + str ( k + 1 ) + \",\" + str ( i + 1 ) + \": \" )) mat1 . append ( l ) h = float ( input ( \"Masukkan Hasil: \" )) b . append ( h ) a . append ( mat1 ) n = 3 x = [ 0 , 0 , 0 ] print ( x ) for i in range ( 0 , 100 ): x = seidel ( a , x , b ) print ( x ) Output: Masukkan Panjang Matrix: 3 Masukkan a1,1: 4 Masukkan a1,2: -1 Masukkan a1,3: 1 Masukkan Hasil: 7 Masukkan a2,1: 4 Masukkan a2,2: -8 Masukkan a2,3: 1 Masukkan Hasil: -21 Masukkan a3,1: -2 Masukkan a3,2: 1 Masukkan a3,3: 5 Masukkan Hasil: 15 [0, 0, 0] [1.75, 3.5, 3.0] [1.875, 3.9375, 2.9625] [1.99375, 3.9921875, 2.9990625] [1.99828125, 3.9990234375, 2.9995078125] [1.99987890625, 3.9998779296875, 2.9999759765625003] [1.99997548828125, 3.9999847412109375, 2.999993247070312] [1.9999978735351562, 3.9999980926513667, 2.999999530883789] [1.9999996404418945, 3.9999997615814205, 2.9999999038604734] [1.9999999644302369, 3.9999999701976776, 2.9999999917325595] [1.9999999946162794, 3.9999999962747097, 2.99999999859157] [1.9999999994207849, 3.9999999995343387, 2.9999999998614464] [1.9999999999182232, 3.999999999941793, 2.999999999978931] [1.9999999999907154, 3.999999999992724, 2.9999999999977414] [1.9999999999987457, 3.9999999999990905, 2.9999999999996803] [1.9999999999998526, 3.9999999999998863, 2.9999999999999636] [1.9999999999999807, 3.999999999999986, 2.999999999999995] [1.9999999999999978, 3.9999999999999987, 2.9999999999999996] [1.9999999999999996, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] [2.0, 4.0, 3.0] Dari soal diatas persamaan yang dipilih adalah 4x-y+z=7, 4x-8y+z=-21 dan -2x+y+5z=15. Iterasi yang digunakan sebanyak 100 iterasi sehingga dapat menghasilkan x=2,y=4 dan z=3. Sekian dan Terima Kasih","title":"Listing Program"},{"location":"Tugas5/","text":"Methode Euler \u00b6 \u200b Dalam matematika dan ilmu komputasi , metode Euler (juga disebut metode forward Euler ) adalah prosedur numerik orde pertama untuk menyelesaikan persamaan diferensial biasa (ODE) dengan nilai awal yang diberikan. Ini adalah metode eksplisit paling dasar untuk integrasi numerik persamaan diferensial biasa dan merupakan metode Runge-Kutta paling sederhana. Metode Euler dinamai Leonhard Euler , yang memperlakukannya dalam bukunya Institutionum calculi integralis (diterbitkan 1768-1870). [ 1] \u200b Metode Euler adalah metode urutan pertama, yang berarti bahwa kesalahan lokal (kesalahan per langkah) sebanding dengan kuadrat ukuran langkah, dan kesalahan global (kesalahan pada waktu tertentu) sebanding dengan ukuran langkah. Metode Euler sering berfungsi sebagai dasar untuk membangun metode yang lebih kompleks, misalnya, metode prediktor-korektor . Contoh soal \u00b6 Buatlah program untuk menyelesaikan persamaan differensial biasa berikut dengan menggunakan metode Euler Untuk menentukan y(1.01), y(1.02) dan y(1.03). Code Program dengan Python \u00b6 print ( \"f(x,y)=1+x^2\" ) print ( \"yi+1 = y1 + hf(xi+yi)\" ) x1 = float ( input ( \"Masukkan x1= \" )) x2 = float ( input ( \"Masukkan x2= \" )) h = 1.01 - x1 #Langsung saya atur sendiri karena yang dicari f(x,y) nilai x-nya=1.01 n = 4 #jumlah x ada 4 yaitu 1, 1.01, 1.02, 1.03 xi = - 4 hasil = xi y = 0 for i in range ( n ): print ( \"hasil dari y\" + str ( i ) + \"= \" + str ( hasil )) hasil = xi + h * ( 1 + ( x1 + y ) ** 2 ) y += h xi = hasil pada bagian pertama terdapat variable x1 adalah x awal dan x2 merupakan x akhir. karena di soal terdapat nx=3 yaitu x0=1, x1=1,01, x3=1,02 x2=1,03 maka h= xn-x0/n, hasilnya h = 0.01. xi adalah hasil awal yang kemudian akan dimasukkan pada prosess iterasi. Karena rumus eurel adalah y1 = y0 +h(f(x,y)) maka rumus barunya adalah y1=y0+h(1+x^2). variable y digunakan untuk penambahan nilai x agar selalu bertambah 0.01. < script type = \"text/x-mathjax-config\" > MathJax . Hub . Config ({ tex2jax : { inlineMath : [[ '$$' , '$$' ],[ '$' , '$' ]]} }); </ script > < script type = \"text/javascript\" async src = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\" > </ script >","title":"Metode Euler"},{"location":"Tugas5/#methode-euler","text":"\u200b Dalam matematika dan ilmu komputasi , metode Euler (juga disebut metode forward Euler ) adalah prosedur numerik orde pertama untuk menyelesaikan persamaan diferensial biasa (ODE) dengan nilai awal yang diberikan. Ini adalah metode eksplisit paling dasar untuk integrasi numerik persamaan diferensial biasa dan merupakan metode Runge-Kutta paling sederhana. Metode Euler dinamai Leonhard Euler , yang memperlakukannya dalam bukunya Institutionum calculi integralis (diterbitkan 1768-1870). [ 1] \u200b Metode Euler adalah metode urutan pertama, yang berarti bahwa kesalahan lokal (kesalahan per langkah) sebanding dengan kuadrat ukuran langkah, dan kesalahan global (kesalahan pada waktu tertentu) sebanding dengan ukuran langkah. Metode Euler sering berfungsi sebagai dasar untuk membangun metode yang lebih kompleks, misalnya, metode prediktor-korektor .","title":"Methode Euler"},{"location":"Tugas5/#contoh-soal","text":"Buatlah program untuk menyelesaikan persamaan differensial biasa berikut dengan menggunakan metode Euler Untuk menentukan y(1.01), y(1.02) dan y(1.03).","title":"Contoh soal"},{"location":"Tugas5/#code-program-dengan-python","text":"print ( \"f(x,y)=1+x^2\" ) print ( \"yi+1 = y1 + hf(xi+yi)\" ) x1 = float ( input ( \"Masukkan x1= \" )) x2 = float ( input ( \"Masukkan x2= \" )) h = 1.01 - x1 #Langsung saya atur sendiri karena yang dicari f(x,y) nilai x-nya=1.01 n = 4 #jumlah x ada 4 yaitu 1, 1.01, 1.02, 1.03 xi = - 4 hasil = xi y = 0 for i in range ( n ): print ( \"hasil dari y\" + str ( i ) + \"= \" + str ( hasil )) hasil = xi + h * ( 1 + ( x1 + y ) ** 2 ) y += h xi = hasil pada bagian pertama terdapat variable x1 adalah x awal dan x2 merupakan x akhir. karena di soal terdapat nx=3 yaitu x0=1, x1=1,01, x3=1,02 x2=1,03 maka h= xn-x0/n, hasilnya h = 0.01. xi adalah hasil awal yang kemudian akan dimasukkan pada prosess iterasi. Karena rumus eurel adalah y1 = y0 +h(f(x,y)) maka rumus barunya adalah y1=y0+h(1+x^2). variable y digunakan untuk penambahan nilai x agar selalu bertambah 0.01. < script type = \"text/x-mathjax-config\" > MathJax . Hub . Config ({ tex2jax : { inlineMath : [[ '$$' , '$$' ],[ '$' , '$' ]]} }); </ script > < script type = \"text/javascript\" async src = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\" > </ script >","title":"Code Program dengan Python"},{"location":"Untitled8 (1)/","text":"MISSING VELUE \u00b6 cara mengisi data yang hilang adalah dengan menghitung jarak nya terlebih dahulu ,data yang hilang berkemungkinan akan bermasalah pada kemuadian hari. ada dua cara mengatasi missing velue dengan cara mengahapus data yang hilang ketika data tersebut dibawah 5% atau bisa dengan cara knn untuk mengisinyanya kembali ##### berikut langkah dari algoritma K-NN kita harus mengambil 2 tetangga terdekat dengan missing vellue hitung jarak tetangga tadi lalu urutkan dari yang terbesar ke yang terkecil ambil urutan yang terkecil lalu rata rata #### berikut ini cara mengatasi missing velue dengan python import pandas as pd import numpy as np dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} df = pd . DataFrame ( dict ) df . isnull () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 False False True 1 False False False 2 True False False 3 False True False # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # creating bool series True for NaN values bool_series = pd . isnull ( data [ \"Gender\" ]) # filtering data # displaying data only with Gender = NaN data [ bool_series ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 20 Lois NaN 4/22/1995 7:18 PM 64714 4.934 True Legal 22 Joshua NaN 3/8/2012 1:58 AM 90816 18.816 True Client Services 27 Scott NaN 7/11/1991 6:58 PM 122367 5.218 False Legal 31 Joyce NaN 2/20/2005 2:40 PM 88657 12.752 False Product 41 Christine NaN 6/28/2015 1:08 AM 66582 11.308 True Business Development 49 Chris NaN 1/24/1980 12:13 PM 113590 3.055 False Sales 51 NaN NaN 12/17/2011 8:29 AM 41126 14.009 NaN Sales 53 Alan NaN 3/3/2014 1:28 PM 40341 17.578 True Finance 60 Paula NaN 11/23/2005 2:01 PM 48866 4.271 False Distribution 64 Kathleen NaN 4/11/1990 6:46 PM 77834 18.771 False Business Development 69 Irene NaN 7/14/2015 4:31 PM 100863 4.382 True Finance 70 Todd NaN 6/10/2003 2:26 PM 84692 6.617 False Client Services 80 Gerald NaN 3/17/1995 12:50 AM 137126 15.602 True Sales 86 Annie NaN 9/29/2007 12:11 AM 103495 17.290 True Business Development 90 Janice NaN 8/21/1997 5:12 AM 91719 11.583 True Legal 91 James NaN 1/26/2005 11:00 PM 128771 8.309 False NaN 93 Virginia NaN 5/7/1994 5:58 PM 111858 1.601 True Legal 97 Laura NaN 7/19/2014 9:23 PM 140371 10.620 True Marketing 108 Russell NaN 5/5/1988 7:57 AM 133980 12.396 True Legal 121 Kathleen NaN 5/9/2016 8:55 AM 119735 18.740 False Product 143 Teresa NaN 1/28/2016 10:55 AM 140013 8.689 True Engineering 144 Nicole NaN 3/5/1982 2:28 PM 122717 12.452 False Sales 148 Patrick NaN 7/14/1991 2:24 AM 124488 14.837 True Sales 151 Brandon NaN 11/3/1997 8:17 PM 121333 15.295 False Business Development 153 Victor NaN 3/10/2011 8:40 PM 84546 10.489 True Finance 159 James NaN 11/22/1983 10:52 PM 68501 14.316 False Marketing 161 Marilyn NaN 8/22/1999 9:09 AM 103386 11.451 False Distribution 168 Peter NaN 9/3/1987 5:59 PM 38989 7.017 True Marketing 174 NaN NaN 9/18/2007 6:59 PM 40297 6.185 NaN Client Services 183 Ruth NaN 5/18/1999 5:56 AM 98233 2.518 True Distribution ... ... ... ... ... ... ... ... ... 769 Samuel NaN 10/7/2002 3:08 AM 141305 9.849 True Marketing 783 NaN NaN 4/15/1991 3:39 AM 132505 13.592 NaN Product 788 Michelle NaN 3/31/2012 6:28 AM 124441 16.353 False Business Development 792 Anne NaN 4/18/1996 11:57 PM 122762 9.564 False Distribution 795 Theresa NaN 10/7/1995 10:16 AM 42025 3.319 True Human Resources 815 Maria NaN 1/18/1986 8:36 PM 106562 4.000 False Human Resources 825 Robert NaN 12/4/2000 1:20 AM 69267 5.890 True Sales 826 NaN NaN 8/1/1988 1:35 AM 87103 5.665 NaN NaN 827 Jesse NaN 7/16/2014 2:24 AM 98811 7.487 False Legal 834 Carl NaN 2/11/1982 7:54 AM 49325 2.071 True Business Development 844 Maria NaN 6/19/1985 1:48 AM 148857 8.738 False Legal 847 Nicole NaN 5/2/1981 12:03 PM 41449 4.707 False Finance 855 Phillip NaN 10/20/2003 11:09 AM 89700 2.277 True NaN 856 Bonnie NaN 1/18/2006 6:52 PM 108946 12.211 False Finance 870 Cynthia NaN 11/19/1996 10:40 PM 107816 18.751 False Marketing 876 Terry NaN 9/11/1992 4:41 PM 41238 8.219 False Marketing 880 Robert NaN 5/25/2007 3:17 AM 90998 8.382 False Finance 882 Sara NaN 11/18/2014 2:47 PM 135990 14.344 True Distribution 895 Janice NaN 11/19/1991 6:02 PM 139791 16.968 False Business Development 897 Kenneth NaN 2/28/1994 10:10 AM 95296 10.146 False Finance 923 Irene NaN 2/28/1991 10:23 PM 135369 4.380 False Business Development 937 Aaron NaN 1/22/1986 7:39 PM 63126 18.424 False Client Services 938 Mark NaN 9/9/2006 12:27 PM 44836 2.657 False Client Services 939 Ralph NaN 7/28/1995 6:53 PM 70635 2.147 False Client Services 945 Gerald NaN 4/15/1989 12:44 PM 93712 17.426 True Distribution 961 Antonio NaN 6/18/1989 9:37 PM 103050 3.050 False Legal 972 Victor NaN 7/28/2006 2:49 PM 76381 11.159 True Sales 985 Stephen NaN 7/10/1983 8:10 PM 85668 1.909 False Legal 989 Justin NaN 2/10/1991 4:58 PM 38344 3.794 False Legal 995 Henry NaN 11/23/2014 6:09 AM 132483 16.655 False Distribution 145 rows \u00d7 8 columns # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe using dictionary df = pd . DataFrame ( dict ) # using notnull() function df . notnull () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 True True False 1 True True True 2 False True True 3 True False True .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b v1 v2 v3 v4 v5 10 R 1 1 3 2.0 11 R 1 1 3 3.0 12 R 1 1 3 NaN 13 R 1 1 3 5.0 14 R 1 1 4 1.0 15 R 1 1 4 2.0 16 R 1 1 4 3.0 17 R 1 1 4 4.0 18 R 1 1 4 5.0 19 R 1 1 5 1.0 20 R 1 1 5 2.0 21 R 1 1 5 3.0 22 R 1 1 5 4.0 23 R 1 1 5 5.0 24 L 1 2 1 1.0 # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # creating bool series True for NaN values bool_series = pd . notnull ( data [ \"Gender\" ]) # filtering data # displayind data only with Gender = Not NaN data [ bool_series ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 1 Thomas Male 3/31/1996 6:53 AM 61933 4.170 True NaN 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 7 NaN Female 7/20/2015 10:43 AM 45906 11.598 NaN Finance 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 25 NaN Male 10/8/2012 1:12 AM 37076 18.576 NaN Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal 30 Christina Female 8/6/2002 1:19 PM 118780 9.096 True Engineering 32 NaN Male 8/21/1998 2:27 PM 122340 6.417 NaN NaN 33 Jean Female 12/18/1993 9:07 AM 119082 16.180 False Business Development ... ... ... ... ... ... ... ... ... 966 Louis Male 8/16/2011 5:19 PM 93022 9.146 True Human Resources 967 Thomas Male 3/12/2016 3:10 PM 105681 19.572 False Engineering 968 Louise Female 3/27/1995 10:27 PM 43050 11.671 False Distribution 969 Linda Female 2/4/2010 8:49 PM 44486 17.308 True Engineering 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 855 rows \u00d7 8 columns # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Score Second Score Third Score 0 100.0 30.0 0.0 1 90.0 45.0 40.0 2 0.0 56.0 80.0 3 95.0 0.0 98.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling a missing value with # previous ones df . fillna ( method = 'pad' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Score Second Score Third Score 0 100.0 30.0 NaN 1 90.0 45.0 40.0 2 90.0 56.0 80.0 3 95.0 56.0 98.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling null value using fillna() function df . fillna ( method = 'bfill' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 100.0 30.0 40.0 1 90.0 45.0 40.0 2 95.0 56.0 80.0 3 95.0 NaN 98.0 # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # Printing the first 10 to 24 rows of # the data frame for visualization data [ 10 : 25 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois NaN 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua NaN 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # filling a null values using fillna() data [ \"Gender\" ] . fillna ( \"No Gender\" , inplace = True ) data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 1 Thomas Male 3/31/1996 6:53 AM 61933 4.170 True NaN 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 7 NaN Female 7/20/2015 10:43 AM 45906 11.598 NaN Finance 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois No Gender 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua No Gender 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 25 NaN Male 10/8/2012 1:12 AM 37076 18.576 NaN Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 27 Scott No Gender 7/11/1991 6:58 PM 122367 5.218 False Legal 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal ... ... ... ... ... ... ... ... ... 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 972 Victor No Gender 7/28/2006 2:49 PM 76381 11.159 True Sales 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 985 Stephen No Gender 7/10/1983 8:10 PM 85668 1.909 False Legal 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 989 Justin No Gender 2/10/1991 4:58 PM 38344 3.794 False Legal 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 995 Henry No Gender 11/23/2014 6:09 AM 132483 16.655 False Distribution 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 1000 rows \u00d7 8 columns # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # Printing the first 10 to 24 rows of # the data frame for visualization data [ 10 : 25 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois NaN 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua NaN 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # will replace Nan value in dataframe with value -99 data . replace ( to_replace = np . nan , value = - 99 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 1 Thomas Male 3/31/1996 6:53 AM 61933 4.170 True -99 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 7 -99 Female 7/20/2015 10:43 AM 45906 11.598 -99 Finance 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True -99 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois -99 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua -99 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 -99 Male 6/14/2012 4:19 PM 125792 5.042 -99 -99 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 25 -99 Male 10/8/2012 1:12 AM 37076 18.576 -99 Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 27 Scott -99 7/11/1991 6:58 PM 122367 5.218 False Legal 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal ... ... ... ... ... ... ... ... ... 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 972 Victor -99 7/28/2006 2:49 PM 76381 11.159 True Sales 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 985 Stephen -99 7/10/1983 8:10 PM 85668 1.909 False Legal 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 989 Justin -99 2/10/1991 4:58 PM 38344 3.794 False Legal 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 995 Henry -99 11/23/2014 6:09 AM 132483 16.655 False Distribution 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 1000 rows \u00d7 8 columns # importing pandas as pd import pandas as pd # Creating the dataframe df = pd . DataFrame ({ \"A\" :[ 12 , 4 , 5 , None , 1 ], \"B\" :[ None , 2 , 54 , 3 , None ], \"C\" :[ 20 , 16 , None , 3 , 8 ], \"D\" :[ 14 , 3 , None , None , 6 ]}) # Print the dataframe df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 12.0 NaN 20.0 14.0 1 4.0 2.0 16.0 3.0 2 5.0 54.0 NaN NaN 3 NaN 3.0 3.0 NaN 4 1.0 NaN 8.0 6.0 # to interpolate the missing values df . interpolate ( method = 'linear' , limit_direction = 'forward' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 12.0 NaN 20.0 14.0 1 4.0 2.0 16.0 3.0 2 5.0 54.0 9.5 4.0 3 3.0 3.0 3.0 5.0 4 1.0 3.0 8.0 6.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , 40 , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52 NaN 1 90.0 NaN 40 NaN 2 NaN 45.0 80 NaN 3 95.0 56.0 98 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , 40 , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # using dropna() function df . dropna () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 3 95.0 56.0 98 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52.0 NaN 1 NaN NaN NaN NaN 2 NaN 45.0 80.0 NaN 3 95.0 56.0 98.0 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} df = pd . DataFrame ( dict ) # using dropna() function df . dropna ( how = 'all' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52.0 NaN 2 NaN 45.0 80.0 NaN 3 95.0 56.0 98.0 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ 60 , 67 , 68 , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52.0 60 1 NaN NaN NaN 67 2 NaN 45.0 80.0 68 3 95.0 56.0 98.0 65 import pandas as pd import numpy as np dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ 60 , 67 , 68 , 65 ]} df = pd . DataFrame ( dict ) df . dropna ( axis = 1 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } Fourth Score 0 60 1 67 2 68 3 65 import pandas as pd data = pd . read_csv ( \"employees.csv\" ) new_data = data . dropna ( axis = 0 , how = 'any' ) new_data .dataframe tbody tr th:only-of-type { vertical-align: middle; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal 30 Christina Female 8/6/2002 1:19 PM 118780 9.096 True Engineering 33 Jean Female 12/18/1993 9:07 AM 119082 16.180 False Business Development 34 Jerry Male 1/10/2004 12:56 PM 95734 19.096 False Client Services 35 Theresa Female 10/10/2006 1:12 AM 85182 16.675 False Sales 36 Rachel Female 2/16/2009 8:47 PM 142032 12.599 False Business Development 37 Linda Female 10/19/1981 8:49 PM 57427 9.557 True Client Services 38 Stephanie Female 9/13/1986 1:52 AM 36844 5.574 True Business Development 40 Michael Male 10/10/2008 11:25 AM 99283 2.665 True Distribution ... ... ... ... ... ... ... ... ... 966 Louis Male 8/16/2011 5:19 PM 93022 9.146 True Human Resources 967 Thomas Male 3/12/2016 3:10 PM 105681 19.572 False Engineering 968 Louise Female 3/27/1995 10:27 PM 43050 11.671 False Distribution 969 Linda Female 2/4/2010 8:49 PM 44486 17.308 True Engineering 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 764 rows \u00d7 8 columns","title":"MISSING VELLUES"},{"location":"Untitled8 (1)/#missing-velue","text":"cara mengisi data yang hilang adalah dengan menghitung jarak nya terlebih dahulu ,data yang hilang berkemungkinan akan bermasalah pada kemuadian hari. ada dua cara mengatasi missing velue dengan cara mengahapus data yang hilang ketika data tersebut dibawah 5% atau bisa dengan cara knn untuk mengisinyanya kembali ##### berikut langkah dari algoritma K-NN kita harus mengambil 2 tetangga terdekat dengan missing vellue hitung jarak tetangga tadi lalu urutkan dari yang terbesar ke yang terkecil ambil urutan yang terkecil lalu rata rata #### berikut ini cara mengatasi missing velue dengan python import pandas as pd import numpy as np dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} df = pd . DataFrame ( dict ) df . isnull () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 False False True 1 False False False 2 True False False 3 False True False # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # creating bool series True for NaN values bool_series = pd . isnull ( data [ \"Gender\" ]) # filtering data # displaying data only with Gender = NaN data [ bool_series ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 20 Lois NaN 4/22/1995 7:18 PM 64714 4.934 True Legal 22 Joshua NaN 3/8/2012 1:58 AM 90816 18.816 True Client Services 27 Scott NaN 7/11/1991 6:58 PM 122367 5.218 False Legal 31 Joyce NaN 2/20/2005 2:40 PM 88657 12.752 False Product 41 Christine NaN 6/28/2015 1:08 AM 66582 11.308 True Business Development 49 Chris NaN 1/24/1980 12:13 PM 113590 3.055 False Sales 51 NaN NaN 12/17/2011 8:29 AM 41126 14.009 NaN Sales 53 Alan NaN 3/3/2014 1:28 PM 40341 17.578 True Finance 60 Paula NaN 11/23/2005 2:01 PM 48866 4.271 False Distribution 64 Kathleen NaN 4/11/1990 6:46 PM 77834 18.771 False Business Development 69 Irene NaN 7/14/2015 4:31 PM 100863 4.382 True Finance 70 Todd NaN 6/10/2003 2:26 PM 84692 6.617 False Client Services 80 Gerald NaN 3/17/1995 12:50 AM 137126 15.602 True Sales 86 Annie NaN 9/29/2007 12:11 AM 103495 17.290 True Business Development 90 Janice NaN 8/21/1997 5:12 AM 91719 11.583 True Legal 91 James NaN 1/26/2005 11:00 PM 128771 8.309 False NaN 93 Virginia NaN 5/7/1994 5:58 PM 111858 1.601 True Legal 97 Laura NaN 7/19/2014 9:23 PM 140371 10.620 True Marketing 108 Russell NaN 5/5/1988 7:57 AM 133980 12.396 True Legal 121 Kathleen NaN 5/9/2016 8:55 AM 119735 18.740 False Product 143 Teresa NaN 1/28/2016 10:55 AM 140013 8.689 True Engineering 144 Nicole NaN 3/5/1982 2:28 PM 122717 12.452 False Sales 148 Patrick NaN 7/14/1991 2:24 AM 124488 14.837 True Sales 151 Brandon NaN 11/3/1997 8:17 PM 121333 15.295 False Business Development 153 Victor NaN 3/10/2011 8:40 PM 84546 10.489 True Finance 159 James NaN 11/22/1983 10:52 PM 68501 14.316 False Marketing 161 Marilyn NaN 8/22/1999 9:09 AM 103386 11.451 False Distribution 168 Peter NaN 9/3/1987 5:59 PM 38989 7.017 True Marketing 174 NaN NaN 9/18/2007 6:59 PM 40297 6.185 NaN Client Services 183 Ruth NaN 5/18/1999 5:56 AM 98233 2.518 True Distribution ... ... ... ... ... ... ... ... ... 769 Samuel NaN 10/7/2002 3:08 AM 141305 9.849 True Marketing 783 NaN NaN 4/15/1991 3:39 AM 132505 13.592 NaN Product 788 Michelle NaN 3/31/2012 6:28 AM 124441 16.353 False Business Development 792 Anne NaN 4/18/1996 11:57 PM 122762 9.564 False Distribution 795 Theresa NaN 10/7/1995 10:16 AM 42025 3.319 True Human Resources 815 Maria NaN 1/18/1986 8:36 PM 106562 4.000 False Human Resources 825 Robert NaN 12/4/2000 1:20 AM 69267 5.890 True Sales 826 NaN NaN 8/1/1988 1:35 AM 87103 5.665 NaN NaN 827 Jesse NaN 7/16/2014 2:24 AM 98811 7.487 False Legal 834 Carl NaN 2/11/1982 7:54 AM 49325 2.071 True Business Development 844 Maria NaN 6/19/1985 1:48 AM 148857 8.738 False Legal 847 Nicole NaN 5/2/1981 12:03 PM 41449 4.707 False Finance 855 Phillip NaN 10/20/2003 11:09 AM 89700 2.277 True NaN 856 Bonnie NaN 1/18/2006 6:52 PM 108946 12.211 False Finance 870 Cynthia NaN 11/19/1996 10:40 PM 107816 18.751 False Marketing 876 Terry NaN 9/11/1992 4:41 PM 41238 8.219 False Marketing 880 Robert NaN 5/25/2007 3:17 AM 90998 8.382 False Finance 882 Sara NaN 11/18/2014 2:47 PM 135990 14.344 True Distribution 895 Janice NaN 11/19/1991 6:02 PM 139791 16.968 False Business Development 897 Kenneth NaN 2/28/1994 10:10 AM 95296 10.146 False Finance 923 Irene NaN 2/28/1991 10:23 PM 135369 4.380 False Business Development 937 Aaron NaN 1/22/1986 7:39 PM 63126 18.424 False Client Services 938 Mark NaN 9/9/2006 12:27 PM 44836 2.657 False Client Services 939 Ralph NaN 7/28/1995 6:53 PM 70635 2.147 False Client Services 945 Gerald NaN 4/15/1989 12:44 PM 93712 17.426 True Distribution 961 Antonio NaN 6/18/1989 9:37 PM 103050 3.050 False Legal 972 Victor NaN 7/28/2006 2:49 PM 76381 11.159 True Sales 985 Stephen NaN 7/10/1983 8:10 PM 85668 1.909 False Legal 989 Justin NaN 2/10/1991 4:58 PM 38344 3.794 False Legal 995 Henry NaN 11/23/2014 6:09 AM 132483 16.655 False Distribution 145 rows \u00d7 8 columns # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe using dictionary df = pd . DataFrame ( dict ) # using notnull() function df . notnull () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 True True False 1 True True True 2 False True True 3 True False True .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b v1 v2 v3 v4 v5 10 R 1 1 3 2.0 11 R 1 1 3 3.0 12 R 1 1 3 NaN 13 R 1 1 3 5.0 14 R 1 1 4 1.0 15 R 1 1 4 2.0 16 R 1 1 4 3.0 17 R 1 1 4 4.0 18 R 1 1 4 5.0 19 R 1 1 5 1.0 20 R 1 1 5 2.0 21 R 1 1 5 3.0 22 R 1 1 5 4.0 23 R 1 1 5 5.0 24 L 1 2 1 1.0 # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # creating bool series True for NaN values bool_series = pd . notnull ( data [ \"Gender\" ]) # filtering data # displayind data only with Gender = Not NaN data [ bool_series ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 1 Thomas Male 3/31/1996 6:53 AM 61933 4.170 True NaN 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 7 NaN Female 7/20/2015 10:43 AM 45906 11.598 NaN Finance 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 25 NaN Male 10/8/2012 1:12 AM 37076 18.576 NaN Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal 30 Christina Female 8/6/2002 1:19 PM 118780 9.096 True Engineering 32 NaN Male 8/21/1998 2:27 PM 122340 6.417 NaN NaN 33 Jean Female 12/18/1993 9:07 AM 119082 16.180 False Business Development ... ... ... ... ... ... ... ... ... 966 Louis Male 8/16/2011 5:19 PM 93022 9.146 True Human Resources 967 Thomas Male 3/12/2016 3:10 PM 105681 19.572 False Engineering 968 Louise Female 3/27/1995 10:27 PM 43050 11.671 False Distribution 969 Linda Female 2/4/2010 8:49 PM 44486 17.308 True Engineering 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 855 rows \u00d7 8 columns # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Score Second Score Third Score 0 100.0 30.0 0.0 1 90.0 45.0 40.0 2 0.0 56.0 80.0 3 95.0 0.0 98.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling a missing value with # previous ones df . fillna ( method = 'pad' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Score Second Score Third Score 0 100.0 30.0 NaN 1 90.0 45.0 40.0 2 90.0 56.0 80.0 3 95.0 56.0 98.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling null value using fillna() function df . fillna ( method = 'bfill' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 100.0 30.0 40.0 1 90.0 45.0 40.0 2 95.0 56.0 80.0 3 95.0 NaN 98.0 # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # Printing the first 10 to 24 rows of # the data frame for visualization data [ 10 : 25 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois NaN 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua NaN 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # filling a null values using fillna() data [ \"Gender\" ] . fillna ( \"No Gender\" , inplace = True ) data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 1 Thomas Male 3/31/1996 6:53 AM 61933 4.170 True NaN 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 7 NaN Female 7/20/2015 10:43 AM 45906 11.598 NaN Finance 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois No Gender 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua No Gender 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 25 NaN Male 10/8/2012 1:12 AM 37076 18.576 NaN Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 27 Scott No Gender 7/11/1991 6:58 PM 122367 5.218 False Legal 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal ... ... ... ... ... ... ... ... ... 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 972 Victor No Gender 7/28/2006 2:49 PM 76381 11.159 True Sales 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 985 Stephen No Gender 7/10/1983 8:10 PM 85668 1.909 False Legal 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 989 Justin No Gender 2/10/1991 4:58 PM 38344 3.794 False Legal 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 995 Henry No Gender 11/23/2014 6:09 AM 132483 16.655 False Distribution 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 1000 rows \u00d7 8 columns # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # Printing the first 10 to 24 rows of # the data frame for visualization data [ 10 : 25 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } \u200b First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True NaN 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois NaN 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua NaN 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 NaN Male 6/14/2012 4:19 PM 125792 5.042 NaN NaN 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services # importing pandas package import pandas as pd # making data frame from csv file data = pd . read_csv ( \"employees.csv\" ) # will replace Nan value in dataframe with value -99 data . replace ( to_replace = np . nan , value = - 99 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 1 Thomas Male 3/31/1996 6:53 AM 61933 4.170 True -99 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 7 -99 Female 7/20/2015 10:43 AM 45906 11.598 -99 Finance 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 10 Louise Female 8/12/1980 9:01 AM 63241 15.132 True -99 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 20 Lois -99 4/22/1995 7:18 PM 64714 4.934 True Legal 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 22 Joshua -99 3/8/2012 1:58 AM 90816 18.816 True Client Services 23 -99 Male 6/14/2012 4:19 PM 125792 5.042 -99 -99 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 25 -99 Male 10/8/2012 1:12 AM 37076 18.576 -99 Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 27 Scott -99 7/11/1991 6:58 PM 122367 5.218 False Legal 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal ... ... ... ... ... ... ... ... ... 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 972 Victor -99 7/28/2006 2:49 PM 76381 11.159 True Sales 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 985 Stephen -99 7/10/1983 8:10 PM 85668 1.909 False Legal 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 989 Justin -99 2/10/1991 4:58 PM 38344 3.794 False Legal 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 995 Henry -99 11/23/2014 6:09 AM 132483 16.655 False Distribution 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 1000 rows \u00d7 8 columns # importing pandas as pd import pandas as pd # Creating the dataframe df = pd . DataFrame ({ \"A\" :[ 12 , 4 , 5 , None , 1 ], \"B\" :[ None , 2 , 54 , 3 , None ], \"C\" :[ 20 , 16 , None , 3 , 8 ], \"D\" :[ 14 , 3 , None , None , 6 ]}) # Print the dataframe df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 12.0 NaN 20.0 14.0 1 4.0 2.0 16.0 3.0 2 5.0 54.0 NaN NaN 3 NaN 3.0 3.0 NaN 4 1.0 NaN 8.0 6.0 # to interpolate the missing values df . interpolate ( method = 'linear' , limit_direction = 'forward' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 12.0 NaN 20.0 14.0 1 4.0 2.0 16.0 3.0 2 5.0 54.0 9.5 4.0 3 3.0 3.0 3.0 5.0 4 1.0 3.0 8.0 6.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , 40 , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52 NaN 1 90.0 NaN 40 NaN 2 NaN 45.0 80 NaN 3 95.0 56.0 98 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , 40 , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # using dropna() function df . dropna () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 3 95.0 56.0 98 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52.0 NaN 1 NaN NaN NaN NaN 2 NaN 45.0 80.0 NaN 3 95.0 56.0 98.0 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ np . nan , np . nan , np . nan , 65 ]} df = pd . DataFrame ( dict ) # using dropna() function df . dropna ( how = 'all' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52.0 NaN 2 NaN 45.0 80.0 NaN 3 95.0 56.0 98.0 65.0 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ 60 , 67 , 68 , 65 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } First Score Second Score Third Score Fourth Score 0 100.0 30.0 52.0 60 1 NaN NaN NaN 67 2 NaN 45.0 80.0 68 3 95.0 56.0 98.0 65 import pandas as pd import numpy as np dict = { 'First Score' :[ 100 , np . nan , np . nan , 95 ], 'Second Score' : [ 30 , np . nan , 45 , 56 ], 'Third Score' :[ 52 , np . nan , 80 , 98 ], 'Fourth Score' :[ 60 , 67 , 68 , 65 ]} df = pd . DataFrame ( dict ) df . dropna ( axis = 1 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } Fourth Score 0 60 1 67 2 68 3 65 import pandas as pd data = pd . read_csv ( \"employees.csv\" ) new_data = data . dropna ( axis = 0 , how = 'any' ) new_data .dataframe tbody tr th:only-of-type { vertical-align: middle; } First Name Gender Start Date Last Login Time Salary Bonus % Senior Management Team 0 Douglas Male 8/6/1993 12:42 PM 97308 6.945 True Marketing 2 Maria Female 4/23/1993 11:17 AM 130590 11.858 False Finance 3 Jerry Male 3/4/2005 1:00 PM 138705 9.340 True Finance 4 Larry Male 1/24/1998 4:47 PM 101004 1.389 True Client Services 5 Dennis Male 4/18/1987 1:35 AM 115163 10.125 False Legal 6 Ruby Female 8/17/1987 4:20 PM 65476 10.012 True Product 8 Angela Female 11/22/2005 6:29 AM 95570 18.523 True Engineering 9 Frances Female 8/8/2002 6:51 AM 139852 7.524 True Business Development 11 Julie Female 10/26/1997 3:19 PM 102508 12.637 True Legal 12 Brandon Male 12/1/1980 1:08 AM 112807 17.492 True Human Resources 13 Gary Male 1/27/2008 11:40 PM 109831 5.831 False Sales 14 Kimberly Female 1/14/1999 7:13 AM 41426 14.543 True Finance 15 Lillian Female 6/5/2016 6:09 AM 59414 1.256 False Product 16 Jeremy Male 9/21/2010 5:56 AM 90370 7.369 False Human Resources 17 Shawn Male 12/7/1986 7:45 PM 111737 6.414 False Product 18 Diana Female 10/23/1981 10:27 AM 132940 19.082 False Client Services 19 Donna Female 7/22/2010 3:48 AM 81014 1.894 False Product 21 Matthew Male 9/5/1995 2:12 AM 100612 13.645 False Marketing 24 John Male 7/1/1992 10:08 PM 97950 13.873 False Client Services 26 Craig Male 2/27/2000 7:45 AM 37598 7.757 True Marketing 28 Terry Male 11/27/1981 6:30 PM 124008 13.464 True Client Services 29 Benjamin Male 1/26/2005 10:06 PM 79529 7.008 True Legal 30 Christina Female 8/6/2002 1:19 PM 118780 9.096 True Engineering 33 Jean Female 12/18/1993 9:07 AM 119082 16.180 False Business Development 34 Jerry Male 1/10/2004 12:56 PM 95734 19.096 False Client Services 35 Theresa Female 10/10/2006 1:12 AM 85182 16.675 False Sales 36 Rachel Female 2/16/2009 8:47 PM 142032 12.599 False Business Development 37 Linda Female 10/19/1981 8:49 PM 57427 9.557 True Client Services 38 Stephanie Female 9/13/1986 1:52 AM 36844 5.574 True Business Development 40 Michael Male 10/10/2008 11:25 AM 99283 2.665 True Distribution ... ... ... ... ... ... ... ... ... 966 Louis Male 8/16/2011 5:19 PM 93022 9.146 True Human Resources 967 Thomas Male 3/12/2016 3:10 PM 105681 19.572 False Engineering 968 Louise Female 3/27/1995 10:27 PM 43050 11.671 False Distribution 969 Linda Female 2/4/2010 8:49 PM 44486 17.308 True Engineering 970 Alice Female 9/3/1988 8:54 PM 63571 15.397 True Product 971 Patrick Male 12/30/2002 2:01 AM 75423 5.368 True Business Development 973 Russell Male 5/10/2013 11:08 PM 137359 11.105 False Business Development 974 Harry Male 8/30/2011 6:31 PM 67656 16.455 True Client Services 975 Susan Female 4/7/1995 10:05 PM 92436 12.467 False Sales 976 Denise Female 10/19/1992 5:42 AM 137954 4.195 True Legal 977 Sarah Female 12/4/1995 9:16 AM 124566 5.949 False Product 978 Sean Male 1/17/1983 2:23 PM 66146 11.178 False Human Resources 979 Ernest Male 7/20/2013 6:41 AM 142935 13.198 True Product 980 Kimberly Female 1/26/2013 12:57 AM 46233 8.862 True Engineering 981 James Male 1/15/1993 5:19 PM 148985 19.280 False Legal 982 Rose Female 4/6/1982 10:43 AM 91411 8.639 True Human Resources 983 John Male 12/23/1982 10:35 PM 146907 11.738 False Engineering 984 Maria Female 10/15/2011 4:53 PM 43455 13.040 False Engineering 986 Donna Female 11/26/1982 7:04 AM 82871 17.999 False Marketing 987 Gloria Female 12/8/2014 5:08 AM 136709 10.331 True Finance 988 Alice Female 10/5/2004 9:34 AM 47638 11.209 False Human Resources 990 Robin Female 7/24/1987 1:35 PM 100765 10.982 True Client Services 991 Rose Female 8/25/2002 5:12 AM 134505 11.051 True Marketing 992 Anthony Male 10/16/2011 8:35 AM 112769 11.625 True Finance 993 Tina Female 5/15/1997 3:53 PM 56450 19.040 True Engineering 994 George Male 6/21/2013 5:47 PM 98874 4.479 True Marketing 996 Phillip Male 1/31/1984 6:30 AM 42392 19.675 False Finance 997 Russell Male 5/20/2013 12:39 PM 96914 1.421 False Product 998 Larry Male 4/20/2013 4:45 PM 60500 11.985 False Business Development 999 Albert Male 5/15/2012 6:24 PM 129949 10.169 True Sales 764 rows \u00d7 8 columns","title":"MISSING VELUE"},{"location":"clustering/","text":"CLUSTERING CATEGORICAL DATA \u00b6 Clustering adalah sebuah proses untuk mengelompokan data ke dalam beberapa cluster atau kelompok sehingga data dalam satu cluster memiliki tingkat kemiripan yang maksimum dan data antar cluster memiliki kemiripan yang minimum. Metode K-Means Clustering \u00b6 K-Means adalah salah satu algoritma clustering / pengelompokan data yang bersifat Unsupervised Learning, yang berarti masukan dari algoritma ini menerima data tanpa label kelas. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. Karakteristik dari algoritma ini adalah : Memiliki n buah data Input berupa jumlah data dan jumlah cluster (kelompok) Pada setiap cluster / kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut. Algoritma K-Means \u00b6 Secara sederhana algoritma K-Means dimulai dari tahap berikut : Pilih K buah titik centroid. Menghitung jarak data dengan centroid. Update nilai titik centroid. Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah. Rumus K-Means \u00b6 Metode K-Modes \u00b6 K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster. Metode K-Prototype \u00b6 Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu. Algoritma K-Prototype \u00b6 Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek Tahap 1: Tentukan K dengan inisial kluster z1, z2, ...,zk secara acak dari n buah titik {x1, x2,...,xn} Tahap 2 Hitung jarak seluruh data point pada datas et terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memilik i jarak prototype terdekat dengan object yang diukur. Tahap 3 Hitung titik pusat cluster yang baru setela h semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru Tahap 4 jika titik pusat cluster tidak berubah ata u sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih be rubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek. berikut contoh clustering menggunakan sklearn import pandas as pd import numpy as np from sklearn.cluster import KMeans from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import MinMaxScaler import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline train = pd . read_csv ( 'train.csv' ) train test = pd . read_csv ( 'test.csv' ) test .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 892 3 Kelly, Mr. James male 34.5 0 0 330911 7.8292 NaN Q 1 893 3 Wilkes, Mrs. James (Ellen Needs) female 47.0 1 0 363272 7.0000 NaN S 2 894 2 Myles, Mr. Thomas Francis male 62.0 0 0 240276 9.6875 NaN Q 3 895 3 Wirz, Mr. Albert male 27.0 0 0 315154 8.6625 NaN S 4 896 3 Hirvonen, Mrs. Alexander (Helga E Lindqvist) female 22.0 1 1 3101298 12.2875 NaN S 5 897 3 Svensson, Mr. Johan Cervin male 14.0 0 0 7538 9.2250 NaN S 6 898 3 Connolly, Miss. Kate female 30.0 0 0 330972 7.6292 NaN Q 7 899 2 Caldwell, Mr. Albert Francis male 26.0 1 1 248738 29.0000 NaN S 8 900 3 Abrahim, Mrs. Joseph (Sophie Halaut Easu) female 18.0 0 0 2657 7.2292 NaN C 9 901 3 Davies, Mr. John Samuel male 21.0 2 0 A/4 48871 24.1500 NaN S 10 902 3 Ilieff, Mr. Ylio male NaN 0 0 349220 7.8958 NaN S 11 903 1 Jones, Mr. Charles Cresson male 46.0 0 0 694 26.0000 NaN S 12 904 1 Snyder, Mrs. John Pillsbury (Nelle Stevenson) female 23.0 1 0 21228 82.2667 B45 S 13 905 2 Howard, Mr. Benjamin male 63.0 1 0 24065 26.0000 NaN S 14 906 1 Chaffee, Mrs. Herbert Fuller (Carrie Constance... female 47.0 1 0 W.E.P. 5734 61.1750 E31 S 15 907 2 del Carlo, Mrs. Sebastiano (Argenia Genovesi) female 24.0 1 0 SC/PARIS 2167 27.7208 NaN C 16 908 2 Keane, Mr. Daniel male 35.0 0 0 233734 12.3500 NaN Q 17 909 3 Assaf, Mr. Gerios male 21.0 0 0 2692 7.2250 NaN C 18 910 3 Ilmakangas, Miss. Ida Livija female 27.0 1 0 STON/O2. 3101270 7.9250 NaN S 19 911 3 Assaf Khalil, Mrs. Mariana (Miriam\")\" female 45.0 0 0 2696 7.2250 NaN C 20 912 1 Rothschild, Mr. Martin male 55.0 1 0 PC 17603 59.4000 NaN C 21 913 3 Olsen, Master. Artur Karl male 9.0 0 1 C 17368 3.1708 NaN S 22 914 1 Flegenheim, Mrs. Alfred (Antoinette) female NaN 0 0 PC 17598 31.6833 NaN S 23 915 1 Williams, Mr. Richard Norris II male 21.0 0 1 PC 17597 61.3792 NaN C 24 916 1 Ryerson, Mrs. Arthur Larned (Emily Maria Borie) female 48.0 1 3 PC 17608 262.3750 B57 B59 B63 B66 C 25 917 3 Robins, Mr. Alexander A male 50.0 1 0 A/5. 3337 14.5000 NaN S 26 918 1 Ostby, Miss. Helene Ragnhild female 22.0 0 1 113509 61.9792 B36 C 27 919 3 Daher, Mr. Shedid male 22.5 0 0 2698 7.2250 NaN C 28 920 1 Brady, Mr. John Bertram male 41.0 0 0 113054 30.5000 A21 S 29 921 3 Samaan, Mr. Elias male NaN 2 0 2662 21.6792 NaN C ... ... ... ... ... ... ... ... ... ... ... ... 388 1280 3 Canavan, Mr. Patrick male 21.0 0 0 364858 7.7500 NaN Q 389 1281 3 Palsson, Master. Paul Folke male 6.0 3 1 349909 21.0750 NaN S 390 1282 1 Payne, Mr. Vivian Ponsonby male 23.0 0 0 12749 93.5000 B24 S 391 1283 1 Lines, Mrs. Ernest H (Elizabeth Lindsey James) female 51.0 0 1 PC 17592 39.4000 D28 S 392 1284 3 Abbott, Master. Eugene Joseph male 13.0 0 2 C.A. 2673 20.2500 NaN S 393 1285 2 Gilbert, Mr. William male 47.0 0 0 C.A. 30769 10.5000 NaN S 394 1286 3 Kink-Heilmann, Mr. Anton male 29.0 3 1 315153 22.0250 NaN S 395 1287 1 Smith, Mrs. Lucien Philip (Mary Eloise Hughes) female 18.0 1 0 13695 60.0000 C31 S 396 1288 3 Colbert, Mr. Patrick male 24.0 0 0 371109 7.2500 NaN Q 397 1289 1 Frolicher-Stehli, Mrs. Maxmillian (Margaretha ... female 48.0 1 1 13567 79.2000 B41 C 398 1290 3 Larsson-Rondberg, Mr. Edvard A male 22.0 0 0 347065 7.7750 NaN S 399 1291 3 Conlon, Mr. Thomas Henry male 31.0 0 0 21332 7.7333 NaN Q 400 1292 1 Bonnell, Miss. Caroline female 30.0 0 0 36928 164.8667 C7 S 401 1293 2 Gale, Mr. Harry male 38.0 1 0 28664 21.0000 NaN S 402 1294 1 Gibson, Miss. Dorothy Winifred female 22.0 0 1 112378 59.4000 NaN C 403 1295 1 Carrau, Mr. Jose Pedro male 17.0 0 0 113059 47.1000 NaN S 404 1296 1 Frauenthal, Mr. Isaac Gerald male 43.0 1 0 17765 27.7208 D40 C 405 1297 2 Nourney, Mr. Alfred (Baron von Drachstedt\")\" male 20.0 0 0 SC/PARIS 2166 13.8625 D38 C 406 1298 2 Ware, Mr. William Jeffery male 23.0 1 0 28666 10.5000 NaN S 407 1299 1 Widener, Mr. George Dunton male 50.0 1 1 113503 211.5000 C80 C 408 1300 3 Riordan, Miss. Johanna Hannah\"\" female NaN 0 0 334915 7.7208 NaN Q 409 1301 3 Peacock, Miss. Treasteall female 3.0 1 1 SOTON/O.Q. 3101315 13.7750 NaN S 410 1302 3 Naughton, Miss. Hannah female NaN 0 0 365237 7.7500 NaN Q 411 1303 1 Minahan, Mrs. William Edward (Lillian E Thorpe) female 37.0 1 0 19928 90.0000 C78 Q 412 1304 3 Henriksson, Miss. Jenny Lovisa female 28.0 0 0 347086 7.7750 NaN S 413 1305 3 Spector, Mr. Woolf male NaN 0 0 A.5. 3236 8.0500 NaN S 414 1306 1 Oliva y Ocana, Dona. Fermina female 39.0 0 0 PC 17758 108.9000 C105 C 415 1307 3 Saether, Mr. Simon Sivertsen male 38.5 0 0 SOTON/O.Q. 3101262 7.2500 NaN S 416 1308 3 Ware, Mr. Frederick male NaN 0 0 359309 8.0500 NaN S 417 1309 3 Peter, Master. Michael J male NaN 1 1 2668 22.3583 NaN C 418 rows \u00d7 11 columns print ( \"***** Train_Set *****\" ) print ( train . head ()) print ( \" \\n \" ) print ( \"***** Test_Set *****\" ) print ( test . head ()) ***** Train_Set ***** PassengerId Survived Pclass \\ 0 1 0 3 1 2 1 1 2 3 1 3 3 4 1 1 4 5 0 3 Name Sex Age SibSp \\ 0 Braund, Mr. Owen Harris male 22.0 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 2 Heikkinen, Miss. Laina female 26.0 0 3 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 4 Allen, Mr. William Henry male 35.0 0 Parch Ticket Fare Cabin Embarked 0 0 A/5 21171 7.2500 NaN S 1 0 PC 17599 71.2833 C85 C 2 0 STON/O2. 3101282 7.9250 NaN S 3 0 113803 53.1000 C123 S 4 0 373450 8.0500 NaN S \u200b \u200b * Test_Set *** \u200b PassengerId Pclass Name Sex \\ \u200b 0 892 3 Kelly, Mr. James male \u200b 1 893 3 Wilkes, Mrs. James (Ellen Needs) female \u200b 2 894 2 Myles, Mr. Thomas Francis male \u200b 3 895 3 Wirz, Mr. Albert male \u200b 4 896 3 Hirvonen, Mrs. Alexander (Helga E Lindqvist) female \u200b \u200b Age SibSp Parch Ticket Fare Cabin Embarked \u200b 0 34.5 0 0 330911 7.8292 NaN Q \u200b 1 47.0 1 0 363272 7.0000 NaN S \u200b 2 62.0 0 0 240276 9.6875 NaN Q \u200b 3 27.0 0 0 315154 8.6625 NaN S \u200b 4 22.0 1 1 3101298 12.2875 NaN S print ( \"***** Train_Set *****\" ) print ( train . describe ()) print ( \" \\n \" ) print ( \"***** Test_Set *****\" ) print ( test . describe ()) ***** Train_Set ***** PassengerId Survived Pclass Age SibSp \\ count 891.000000 891.000000 891.000000 714.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 std 257.353842 0.486592 0.836071 14.526497 1.102743 min 1.000000 0.000000 1.000000 0.420000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 50% 446.000000 0.000000 3.000000 28.000000 0.000000 75% 668.500000 1.000000 3.000000 38.000000 1.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 Parch Fare count 891.000000 891.000000 mean 0.381594 32.204208 std 0.806057 49.693429 min 0.000000 0.000000 25% 0.000000 7.910400 50% 0.000000 14.454200 75% 0.000000 31.000000 max 6.000000 512.329200 \u200b \u200b * Test_Set *** \u200b PassengerId Pclass Age SibSp Parch Fare \u200b count 418.000000 418.000000 332.000000 418.000000 418.000000 417.000000 \u200b mean 1100.500000 2.265550 30.272590 0.447368 0.392344 35.627188 \u200b std 120.810458 0.841838 14.181209 0.896760 0.981429 55.907576 \u200b min 892.000000 1.000000 0.170000 0.000000 0.000000 0.000000 \u200b 25% 996.250000 1.000000 21.000000 0.000000 0.000000 7.895800 \u200b 50% 1100.500000 3.000000 27.000000 0.000000 0.000000 14.454200 \u200b 75% 1204.750000 3.000000 39.000000 1.000000 0.000000 31.500000 \u200b max 1309.000000 3.000000 76.000000 8.000000 9.000000 512.329200 print ( train . columns . values ) [ 'PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare' 'Cabin' 'Embarked' ] train . isna () . head () ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare' 'Cabin' 'Embarked'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 False False False False False False False False False False True False 1 False False False False False False False False False False False False 2 False False False False False False False False False False True False 3 False False False False False False False False False False False False 4 False False False False False False False False False False True False print ( \"*****In the train set*****\" ) print ( train . isna () . sum ()) print ( \" \\n \" ) print ( \"*****In the test set*****\" ) print ( test . isna () . sum ()) *****In the train set***** PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 \u200b \u200b * In the test set *** \u200b PassengerId 0 \u200b Pclass 0 \u200b Name 0 \u200b Sex 0 \u200b Age 86 \u200b SibSp 0 \u200b Parch 0 \u200b Ticket 0 \u200b Fare 1 \u200b Cabin 327 \u200b Embarked 0 \u200b dtype: int64 train . fillna ( train . mean (), inplace = True ) test . fillna ( test . mean (), inplace = True ) print ( train . isna () . sum ()) PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 0 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 train [ 'Ticket' ] . head () 0 A/5 21171 1 PC 17599 2 STON/O2. 3101282 3 113803 4 373450 Name: Ticket, dtype: object train [ 'Cabin' ] . head () 0 NaN 1 C85 2 NaN 3 C123 4 NaN Name: Cabin, dtype: object train [[ 'Pclass' , 'Survived' ]] . groupby ([ 'Pclass' ], as_index = False ) . mean () . sort_values ( by = 'Survived' , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Pclass Survived 0 1 0.629630 1 2 0.472826 2 3 0.242363 train [[ \"Sex\" , \"Survived\" ]] . groupby ([ 'Sex' ], as_index = False ) . mean () . sort_values ( by = 'Survived' , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex Survived 0 female 0.742038 1 male 0.188908 train [[ \"SibSp\" , \"Survived\" ]] . groupby ([ 'SibSp' ], as_index = False ) . mean () . sort_values ( by = 'Survived' , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } SibSp Survived 1 1 0.535885 2 2 0.464286 0 0 0.345395 3 3 0.250000 4 4 0.166667 5 5 0.000000 6 8 0.000000 g = sns . FacetGrid ( train , col = 'Survived' ) g . map ( plt . hist , 'Age' , bins = 20 ) <seaborn.axisgrid.FacetGrid at 0x19449c70a20> grid = sns . FacetGrid ( train , col = 'Survived' , row = 'Pclass' , size = 2.2 , aspect = 1.6 ) grid . map ( plt . hist , 'Age' , alpha =. 5 , bins = 20 ) grid . add_legend (); F:\\anaqonda\\lib\\site-packages\\seaborn\\axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) train . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Name 891 non-null object Sex 891 non-null object Age 891 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Ticket 891 non-null object Fare 891 non-null float64 Cabin 204 non-null object Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.6+ KB train = train . drop ([ 'Name' , 'Ticket' , 'Cabin' , 'Embarked' ], axis = 1 ) test = test . drop ([ 'Name' , 'Ticket' , 'Cabin' , 'Embarked' ], axis = 1 ) labelEncoder = LabelEncoder () labelEncoder . fit ( train [ 'Sex' ]) labelEncoder . fit ( test [ 'Sex' ]) train [ 'Sex' ] = labelEncoder . transform ( train [ 'Sex' ]) test [ 'Sex' ] = labelEncoder . transform ( test [ 'Sex' ]) train . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 891 entries, 0 to 890 Data columns (total 8 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Sex 891 non-null int32 Age 891 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Fare 891 non-null float64 dtypes: float64(2), int32(1), int64(5) memory usage: 52.3 KB test . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 418 entries, 0 to 417 Data columns (total 7 columns): PassengerId 418 non-null int64 Pclass 418 non-null int64 Sex 418 non-null int32 Age 418 non-null float64 SibSp 418 non-null int64 Parch 418 non-null int64 Fare 418 non-null float64 dtypes: float64(2), int32(1), int64(4) memory usage: 21.3 KB X = np . array ( train . drop ([ 'Survived' ], 1 ) . astype ( float )) y = np . array ( train [ 'Survived' ]) train . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 891 entries, 0 to 890 Data columns (total 8 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Sex 891 non-null int32 Age 891 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Fare 891 non-null float64 dtypes: float64(2), int32(1), int64(5) memory usage: 52.3 KB kmeans = KMeans ( n_clusters = 2 ) kmeans . fit ( X ) KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto', random_state=None, tol=0.0001, verbose=0) correct = 0 for i in range ( len ( X )): predict_me = np . array ( X [ i ] . astype ( float )) predict_me = predict_me . reshape ( - 1 , len ( predict_me )) prediction = kmeans . predict ( predict_me ) if prediction [ 0 ] == y [ i ]: correct += 1 print ( correct / len ( X )) 0.49158249158249157 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"CLUSTERING"},{"location":"clustering/#clustering-categorical-data","text":"Clustering adalah sebuah proses untuk mengelompokan data ke dalam beberapa cluster atau kelompok sehingga data dalam satu cluster memiliki tingkat kemiripan yang maksimum dan data antar cluster memiliki kemiripan yang minimum.","title":"CLUSTERING CATEGORICAL DATA"},{"location":"clustering/#metode-k-means-clustering","text":"K-Means adalah salah satu algoritma clustering / pengelompokan data yang bersifat Unsupervised Learning, yang berarti masukan dari algoritma ini menerima data tanpa label kelas. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. Karakteristik dari algoritma ini adalah : Memiliki n buah data Input berupa jumlah data dan jumlah cluster (kelompok) Pada setiap cluster / kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut.","title":"Metode K-Means Clustering"},{"location":"clustering/#algoritma-k-means","text":"Secara sederhana algoritma K-Means dimulai dari tahap berikut : Pilih K buah titik centroid. Menghitung jarak data dengan centroid. Update nilai titik centroid. Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah.","title":"Algoritma K-Means"},{"location":"clustering/#rumus-k-means","text":"","title":"Rumus K-Means"},{"location":"clustering/#metode-k-modes","text":"K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster.","title":"Metode K-Modes"},{"location":"clustering/#metode-k-prototype","text":"Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu.","title":"Metode K-Prototype"},{"location":"clustering/#algoritma-k-prototype","text":"Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek Tahap 1: Tentukan K dengan inisial kluster z1, z2, ...,zk secara acak dari n buah titik {x1, x2,...,xn} Tahap 2 Hitung jarak seluruh data point pada datas et terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memilik i jarak prototype terdekat dengan object yang diukur. Tahap 3 Hitung titik pusat cluster yang baru setela h semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru Tahap 4 jika titik pusat cluster tidak berubah ata u sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih be rubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek. berikut contoh clustering menggunakan sklearn import pandas as pd import numpy as np from sklearn.cluster import KMeans from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import MinMaxScaler import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline train = pd . read_csv ( 'train.csv' ) train test = pd . read_csv ( 'test.csv' ) test .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 892 3 Kelly, Mr. James male 34.5 0 0 330911 7.8292 NaN Q 1 893 3 Wilkes, Mrs. James (Ellen Needs) female 47.0 1 0 363272 7.0000 NaN S 2 894 2 Myles, Mr. Thomas Francis male 62.0 0 0 240276 9.6875 NaN Q 3 895 3 Wirz, Mr. Albert male 27.0 0 0 315154 8.6625 NaN S 4 896 3 Hirvonen, Mrs. Alexander (Helga E Lindqvist) female 22.0 1 1 3101298 12.2875 NaN S 5 897 3 Svensson, Mr. Johan Cervin male 14.0 0 0 7538 9.2250 NaN S 6 898 3 Connolly, Miss. Kate female 30.0 0 0 330972 7.6292 NaN Q 7 899 2 Caldwell, Mr. Albert Francis male 26.0 1 1 248738 29.0000 NaN S 8 900 3 Abrahim, Mrs. Joseph (Sophie Halaut Easu) female 18.0 0 0 2657 7.2292 NaN C 9 901 3 Davies, Mr. John Samuel male 21.0 2 0 A/4 48871 24.1500 NaN S 10 902 3 Ilieff, Mr. Ylio male NaN 0 0 349220 7.8958 NaN S 11 903 1 Jones, Mr. Charles Cresson male 46.0 0 0 694 26.0000 NaN S 12 904 1 Snyder, Mrs. John Pillsbury (Nelle Stevenson) female 23.0 1 0 21228 82.2667 B45 S 13 905 2 Howard, Mr. Benjamin male 63.0 1 0 24065 26.0000 NaN S 14 906 1 Chaffee, Mrs. Herbert Fuller (Carrie Constance... female 47.0 1 0 W.E.P. 5734 61.1750 E31 S 15 907 2 del Carlo, Mrs. Sebastiano (Argenia Genovesi) female 24.0 1 0 SC/PARIS 2167 27.7208 NaN C 16 908 2 Keane, Mr. Daniel male 35.0 0 0 233734 12.3500 NaN Q 17 909 3 Assaf, Mr. Gerios male 21.0 0 0 2692 7.2250 NaN C 18 910 3 Ilmakangas, Miss. Ida Livija female 27.0 1 0 STON/O2. 3101270 7.9250 NaN S 19 911 3 Assaf Khalil, Mrs. Mariana (Miriam\")\" female 45.0 0 0 2696 7.2250 NaN C 20 912 1 Rothschild, Mr. Martin male 55.0 1 0 PC 17603 59.4000 NaN C 21 913 3 Olsen, Master. Artur Karl male 9.0 0 1 C 17368 3.1708 NaN S 22 914 1 Flegenheim, Mrs. Alfred (Antoinette) female NaN 0 0 PC 17598 31.6833 NaN S 23 915 1 Williams, Mr. Richard Norris II male 21.0 0 1 PC 17597 61.3792 NaN C 24 916 1 Ryerson, Mrs. Arthur Larned (Emily Maria Borie) female 48.0 1 3 PC 17608 262.3750 B57 B59 B63 B66 C 25 917 3 Robins, Mr. Alexander A male 50.0 1 0 A/5. 3337 14.5000 NaN S 26 918 1 Ostby, Miss. Helene Ragnhild female 22.0 0 1 113509 61.9792 B36 C 27 919 3 Daher, Mr. Shedid male 22.5 0 0 2698 7.2250 NaN C 28 920 1 Brady, Mr. John Bertram male 41.0 0 0 113054 30.5000 A21 S 29 921 3 Samaan, Mr. Elias male NaN 2 0 2662 21.6792 NaN C ... ... ... ... ... ... ... ... ... ... ... ... 388 1280 3 Canavan, Mr. Patrick male 21.0 0 0 364858 7.7500 NaN Q 389 1281 3 Palsson, Master. Paul Folke male 6.0 3 1 349909 21.0750 NaN S 390 1282 1 Payne, Mr. Vivian Ponsonby male 23.0 0 0 12749 93.5000 B24 S 391 1283 1 Lines, Mrs. Ernest H (Elizabeth Lindsey James) female 51.0 0 1 PC 17592 39.4000 D28 S 392 1284 3 Abbott, Master. Eugene Joseph male 13.0 0 2 C.A. 2673 20.2500 NaN S 393 1285 2 Gilbert, Mr. William male 47.0 0 0 C.A. 30769 10.5000 NaN S 394 1286 3 Kink-Heilmann, Mr. Anton male 29.0 3 1 315153 22.0250 NaN S 395 1287 1 Smith, Mrs. Lucien Philip (Mary Eloise Hughes) female 18.0 1 0 13695 60.0000 C31 S 396 1288 3 Colbert, Mr. Patrick male 24.0 0 0 371109 7.2500 NaN Q 397 1289 1 Frolicher-Stehli, Mrs. Maxmillian (Margaretha ... female 48.0 1 1 13567 79.2000 B41 C 398 1290 3 Larsson-Rondberg, Mr. Edvard A male 22.0 0 0 347065 7.7750 NaN S 399 1291 3 Conlon, Mr. Thomas Henry male 31.0 0 0 21332 7.7333 NaN Q 400 1292 1 Bonnell, Miss. Caroline female 30.0 0 0 36928 164.8667 C7 S 401 1293 2 Gale, Mr. Harry male 38.0 1 0 28664 21.0000 NaN S 402 1294 1 Gibson, Miss. Dorothy Winifred female 22.0 0 1 112378 59.4000 NaN C 403 1295 1 Carrau, Mr. Jose Pedro male 17.0 0 0 113059 47.1000 NaN S 404 1296 1 Frauenthal, Mr. Isaac Gerald male 43.0 1 0 17765 27.7208 D40 C 405 1297 2 Nourney, Mr. Alfred (Baron von Drachstedt\")\" male 20.0 0 0 SC/PARIS 2166 13.8625 D38 C 406 1298 2 Ware, Mr. William Jeffery male 23.0 1 0 28666 10.5000 NaN S 407 1299 1 Widener, Mr. George Dunton male 50.0 1 1 113503 211.5000 C80 C 408 1300 3 Riordan, Miss. Johanna Hannah\"\" female NaN 0 0 334915 7.7208 NaN Q 409 1301 3 Peacock, Miss. Treasteall female 3.0 1 1 SOTON/O.Q. 3101315 13.7750 NaN S 410 1302 3 Naughton, Miss. Hannah female NaN 0 0 365237 7.7500 NaN Q 411 1303 1 Minahan, Mrs. William Edward (Lillian E Thorpe) female 37.0 1 0 19928 90.0000 C78 Q 412 1304 3 Henriksson, Miss. Jenny Lovisa female 28.0 0 0 347086 7.7750 NaN S 413 1305 3 Spector, Mr. Woolf male NaN 0 0 A.5. 3236 8.0500 NaN S 414 1306 1 Oliva y Ocana, Dona. Fermina female 39.0 0 0 PC 17758 108.9000 C105 C 415 1307 3 Saether, Mr. Simon Sivertsen male 38.5 0 0 SOTON/O.Q. 3101262 7.2500 NaN S 416 1308 3 Ware, Mr. Frederick male NaN 0 0 359309 8.0500 NaN S 417 1309 3 Peter, Master. Michael J male NaN 1 1 2668 22.3583 NaN C 418 rows \u00d7 11 columns print ( \"***** Train_Set *****\" ) print ( train . head ()) print ( \" \\n \" ) print ( \"***** Test_Set *****\" ) print ( test . head ()) ***** Train_Set ***** PassengerId Survived Pclass \\ 0 1 0 3 1 2 1 1 2 3 1 3 3 4 1 1 4 5 0 3 Name Sex Age SibSp \\ 0 Braund, Mr. Owen Harris male 22.0 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 2 Heikkinen, Miss. Laina female 26.0 0 3 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 4 Allen, Mr. William Henry male 35.0 0 Parch Ticket Fare Cabin Embarked 0 0 A/5 21171 7.2500 NaN S 1 0 PC 17599 71.2833 C85 C 2 0 STON/O2. 3101282 7.9250 NaN S 3 0 113803 53.1000 C123 S 4 0 373450 8.0500 NaN S \u200b \u200b * Test_Set *** \u200b PassengerId Pclass Name Sex \\ \u200b 0 892 3 Kelly, Mr. James male \u200b 1 893 3 Wilkes, Mrs. James (Ellen Needs) female \u200b 2 894 2 Myles, Mr. Thomas Francis male \u200b 3 895 3 Wirz, Mr. Albert male \u200b 4 896 3 Hirvonen, Mrs. Alexander (Helga E Lindqvist) female \u200b \u200b Age SibSp Parch Ticket Fare Cabin Embarked \u200b 0 34.5 0 0 330911 7.8292 NaN Q \u200b 1 47.0 1 0 363272 7.0000 NaN S \u200b 2 62.0 0 0 240276 9.6875 NaN Q \u200b 3 27.0 0 0 315154 8.6625 NaN S \u200b 4 22.0 1 1 3101298 12.2875 NaN S print ( \"***** Train_Set *****\" ) print ( train . describe ()) print ( \" \\n \" ) print ( \"***** Test_Set *****\" ) print ( test . describe ()) ***** Train_Set ***** PassengerId Survived Pclass Age SibSp \\ count 891.000000 891.000000 891.000000 714.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 std 257.353842 0.486592 0.836071 14.526497 1.102743 min 1.000000 0.000000 1.000000 0.420000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 50% 446.000000 0.000000 3.000000 28.000000 0.000000 75% 668.500000 1.000000 3.000000 38.000000 1.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 Parch Fare count 891.000000 891.000000 mean 0.381594 32.204208 std 0.806057 49.693429 min 0.000000 0.000000 25% 0.000000 7.910400 50% 0.000000 14.454200 75% 0.000000 31.000000 max 6.000000 512.329200 \u200b \u200b * Test_Set *** \u200b PassengerId Pclass Age SibSp Parch Fare \u200b count 418.000000 418.000000 332.000000 418.000000 418.000000 417.000000 \u200b mean 1100.500000 2.265550 30.272590 0.447368 0.392344 35.627188 \u200b std 120.810458 0.841838 14.181209 0.896760 0.981429 55.907576 \u200b min 892.000000 1.000000 0.170000 0.000000 0.000000 0.000000 \u200b 25% 996.250000 1.000000 21.000000 0.000000 0.000000 7.895800 \u200b 50% 1100.500000 3.000000 27.000000 0.000000 0.000000 14.454200 \u200b 75% 1204.750000 3.000000 39.000000 1.000000 0.000000 31.500000 \u200b max 1309.000000 3.000000 76.000000 8.000000 9.000000 512.329200 print ( train . columns . values ) [ 'PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare' 'Cabin' 'Embarked' ] train . isna () . head () ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare' 'Cabin' 'Embarked'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 False False False False False False False False False False True False 1 False False False False False False False False False False False False 2 False False False False False False False False False False True False 3 False False False False False False False False False False False False 4 False False False False False False False False False False True False print ( \"*****In the train set*****\" ) print ( train . isna () . sum ()) print ( \" \\n \" ) print ( \"*****In the test set*****\" ) print ( test . isna () . sum ()) *****In the train set***** PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 \u200b \u200b * In the test set *** \u200b PassengerId 0 \u200b Pclass 0 \u200b Name 0 \u200b Sex 0 \u200b Age 86 \u200b SibSp 0 \u200b Parch 0 \u200b Ticket 0 \u200b Fare 1 \u200b Cabin 327 \u200b Embarked 0 \u200b dtype: int64 train . fillna ( train . mean (), inplace = True ) test . fillna ( test . mean (), inplace = True ) print ( train . isna () . sum ()) PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 0 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 train [ 'Ticket' ] . head () 0 A/5 21171 1 PC 17599 2 STON/O2. 3101282 3 113803 4 373450 Name: Ticket, dtype: object train [ 'Cabin' ] . head () 0 NaN 1 C85 2 NaN 3 C123 4 NaN Name: Cabin, dtype: object train [[ 'Pclass' , 'Survived' ]] . groupby ([ 'Pclass' ], as_index = False ) . mean () . sort_values ( by = 'Survived' , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Pclass Survived 0 1 0.629630 1 2 0.472826 2 3 0.242363 train [[ \"Sex\" , \"Survived\" ]] . groupby ([ 'Sex' ], as_index = False ) . mean () . sort_values ( by = 'Survived' , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex Survived 0 female 0.742038 1 male 0.188908 train [[ \"SibSp\" , \"Survived\" ]] . groupby ([ 'SibSp' ], as_index = False ) . mean () . sort_values ( by = 'Survived' , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } SibSp Survived 1 1 0.535885 2 2 0.464286 0 0 0.345395 3 3 0.250000 4 4 0.166667 5 5 0.000000 6 8 0.000000 g = sns . FacetGrid ( train , col = 'Survived' ) g . map ( plt . hist , 'Age' , bins = 20 ) <seaborn.axisgrid.FacetGrid at 0x19449c70a20> grid = sns . FacetGrid ( train , col = 'Survived' , row = 'Pclass' , size = 2.2 , aspect = 1.6 ) grid . map ( plt . hist , 'Age' , alpha =. 5 , bins = 20 ) grid . add_legend (); F:\\anaqonda\\lib\\site-packages\\seaborn\\axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) train . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Name 891 non-null object Sex 891 non-null object Age 891 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Ticket 891 non-null object Fare 891 non-null float64 Cabin 204 non-null object Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.6+ KB train = train . drop ([ 'Name' , 'Ticket' , 'Cabin' , 'Embarked' ], axis = 1 ) test = test . drop ([ 'Name' , 'Ticket' , 'Cabin' , 'Embarked' ], axis = 1 ) labelEncoder = LabelEncoder () labelEncoder . fit ( train [ 'Sex' ]) labelEncoder . fit ( test [ 'Sex' ]) train [ 'Sex' ] = labelEncoder . transform ( train [ 'Sex' ]) test [ 'Sex' ] = labelEncoder . transform ( test [ 'Sex' ]) train . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 891 entries, 0 to 890 Data columns (total 8 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Sex 891 non-null int32 Age 891 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Fare 891 non-null float64 dtypes: float64(2), int32(1), int64(5) memory usage: 52.3 KB test . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 418 entries, 0 to 417 Data columns (total 7 columns): PassengerId 418 non-null int64 Pclass 418 non-null int64 Sex 418 non-null int32 Age 418 non-null float64 SibSp 418 non-null int64 Parch 418 non-null int64 Fare 418 non-null float64 dtypes: float64(2), int32(1), int64(4) memory usage: 21.3 KB X = np . array ( train . drop ([ 'Survived' ], 1 ) . astype ( float )) y = np . array ( train [ 'Survived' ]) train . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 891 entries, 0 to 890 Data columns (total 8 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Sex 891 non-null int32 Age 891 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Fare 891 non-null float64 dtypes: float64(2), int32(1), int64(5) memory usage: 52.3 KB kmeans = KMeans ( n_clusters = 2 ) kmeans . fit ( X ) KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto', random_state=None, tol=0.0001, verbose=0) correct = 0 for i in range ( len ( X )): predict_me = np . array ( X [ i ] . astype ( float )) predict_me = predict_me . reshape ( - 1 , len ( predict_me )) prediction = kmeans . predict ( predict_me ) if prediction [ 0 ] == y [ i ]: correct += 1 print ( correct / len ( X )) 0.49158249158249157 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Algoritma K-Prototype"},{"location":"fuzzy clustering/","text":"fuzzy clustering \u00b6 pengertian fuzzy clustering: \u00b6 Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"fuzzy clustering"},{"location":"fuzzy clustering/#fuzzy-clustering","text":"","title":"fuzzy clustering"},{"location":"fuzzy clustering/#pengertian-fuzzy-clustering","text":"Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"pengertian fuzzy clustering:"},{"location":"index2/","text":"selamat datang di halaman tugas penambangan data \u00b6 profil \u00b6 `NAMA : MOH. IMAM WAHYUDI `NIM :180411100007 `KELAS :PENAMBANGAN DATA 5-D `JURUSAN : TEKNIK INFORMATIKA \u200b","title":"index"},{"location":"index2/#selamat-datang-di-halaman-tugas-penambangan-data","text":"","title":"selamat datang di halaman tugas penambangan data"},{"location":"index2/#profil","text":"`NAMA : MOH. IMAM WAHYUDI `NIM :180411100007 `KELAS :PENAMBANGAN DATA 5-D `JURUSAN : TEKNIK INFORMATIKA \u200b","title":"profil"},{"location":"pengertian/","text":"STATISTIK DESKRIPTIF \u00b6 pengertian \u00b6 PENGERTIAN STATISTIK DEKRIPTIF ADALAH metode pengumpulan sebuah data data yang akan menghasilkan informasi yang berguna TIPE STATISTIK DESKRIPTIF \u00b6 MEAN(RATA-RATA) \u00b6 mean atau rata rata adalah sebuah nilai yang jumlah dari seluruah angka atau data dan di bagi banyak data . misal memiliki N data bisa di hitung dengan rumus sebagai berikut $$ \\begin{align} \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i={a_1+a_2+a_3+a_4+........+a_n \\over n} \\end{align} $$ keterangan: x=rata-rata a=nilai ke N n=banyak nilai atau data MEDIAN \u00b6 median merupakan nilai tengah dalam suatu data median disimbolkan Me .menghitung median mempunyai 2 metode yaitu ketika N atau jumlah data ganjil atau genap. berikut rumus median ; $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ ket: me =median atau nilai tengah n=banyak data MODUS \u00b6 MODUS ADALAH nilai yang sering muncul dalam himpunan data.brikut ini rumus mencari modus dalam himpunan data $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ ket; mo=nilai modus tb= tepi bawah b1=selisih frekuensi antara nilai mudus dengan elemen sebelumnya b2=selisih frekuensi antara nilai mudus dengan elemen sesudahnya p= panjang interval varian \u00b6 varian adalah penyebaran nilai dalam suatu data dari rata rata .berikut ini rumus dari varian dalam himpunan data $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ ket: x=rata rata Xi=rata rata dari semua titik data n= banyak dari anggota data standart deviasi \u00b6 Standar deviasi adalah ukuran dispersi himpunan data relatif pada rata-rata atau bisa juga akar kuadrat positif dari varian. berikut ini rumus standat deviasi: $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ skewness( kemiringan ) \u00b6 skewness( kemiringan ) adalah suatu bentuk derajat ketidaksimestrian suatu data.skewness juga di sebut angka atau bilang yang dapat menunjukan ketidakmiringan atau kemiringan suatu data. berikut rumus skewness $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ ket: Xi=titik data x=rata-rata n=jumlah titik distribusi o=standar deviasi QUARTILE \u00b6 quartile merupakan bagian nilai yang di bagi 4 sama rata atau di bagi 25% berikut rumus dari quartile $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ ket: q=nilai quarter n = banyak dari data Berikut penerapan statistik deskriptif di pyton \u00b6 sebelum itu buat data random melalui exsel lalu kita import file tadi seperti di bawah berikut import pandas as pd from scipy import stats df = pd . read_csv ( 'imam.csv' , sep = ';' ) data = { \"stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index () berikut hasil setelah di jalankan stats ukuran baju ukuran sepatu ukaran celana umur Min 18 27 22 20 Max 30 42 36 40 Mean 23.76 34.452 28.812 29.828 Standart Deviasi 3.75 4.64 4.23 6.18 Variasi 14.05 21.53 17.93 38.18 Skewnes 0.08 0.02 0.08 -0 Quantile 1 21 30.75 25 24 Quantile 2 24 34 29 30 Quantile 3 27 39 32 35 Median 24 34 29 30 Modus 21 32 26 24 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"statistik deskriptif"},{"location":"pengertian/#statistik-deskriptif","text":"","title":"STATISTIK DESKRIPTIF"},{"location":"pengertian/#pengertian","text":"PENGERTIAN STATISTIK DEKRIPTIF ADALAH metode pengumpulan sebuah data data yang akan menghasilkan informasi yang berguna","title":"pengertian"},{"location":"pengertian/#tipe-statistik-deskriptif","text":"","title":"TIPE STATISTIK DESKRIPTIF"},{"location":"pengertian/#meanrata-rata","text":"mean atau rata rata adalah sebuah nilai yang jumlah dari seluruah angka atau data dan di bagi banyak data . misal memiliki N data bisa di hitung dengan rumus sebagai berikut $$ \\begin{align} \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i={a_1+a_2+a_3+a_4+........+a_n \\over n} \\end{align} $$ keterangan: x=rata-rata a=nilai ke N n=banyak nilai atau data","title":"MEAN(RATA-RATA)"},{"location":"pengertian/#median","text":"median merupakan nilai tengah dalam suatu data median disimbolkan Me .menghitung median mempunyai 2 metode yaitu ketika N atau jumlah data ganjil atau genap. berikut rumus median ; $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ ket: me =median atau nilai tengah n=banyak data","title":"MEDIAN"},{"location":"pengertian/#modus","text":"MODUS ADALAH nilai yang sering muncul dalam himpunan data.brikut ini rumus mencari modus dalam himpunan data $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ ket; mo=nilai modus tb= tepi bawah b1=selisih frekuensi antara nilai mudus dengan elemen sebelumnya b2=selisih frekuensi antara nilai mudus dengan elemen sesudahnya p= panjang interval","title":"MODUS"},{"location":"pengertian/#varian","text":"varian adalah penyebaran nilai dalam suatu data dari rata rata .berikut ini rumus dari varian dalam himpunan data $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ ket: x=rata rata Xi=rata rata dari semua titik data n= banyak dari anggota data","title":"varian"},{"location":"pengertian/#standart-deviasi","text":"Standar deviasi adalah ukuran dispersi himpunan data relatif pada rata-rata atau bisa juga akar kuadrat positif dari varian. berikut ini rumus standat deviasi: $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$","title":"standart deviasi"},{"location":"pengertian/#skewnesskemiringan","text":"skewness( kemiringan ) adalah suatu bentuk derajat ketidaksimestrian suatu data.skewness juga di sebut angka atau bilang yang dapat menunjukan ketidakmiringan atau kemiringan suatu data. berikut rumus skewness $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ ket: Xi=titik data x=rata-rata n=jumlah titik distribusi o=standar deviasi","title":"skewness(kemiringan)"},{"location":"pengertian/#quartile","text":"quartile merupakan bagian nilai yang di bagi 4 sama rata atau di bagi 25% berikut rumus dari quartile $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ ket: q=nilai quarter n = banyak dari data","title":"QUARTILE"},{"location":"pengertian/#berikut-penerapan-statistik-deskriptif-di-pyton","text":"sebelum itu buat data random melalui exsel lalu kita import file tadi seperti di bawah berikut import pandas as pd from scipy import stats df = pd . read_csv ( 'imam.csv' , sep = ';' ) data = { \"stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index () berikut hasil setelah di jalankan stats ukuran baju ukuran sepatu ukaran celana umur Min 18 27 22 20 Max 30 42 36 40 Mean 23.76 34.452 28.812 29.828 Standart Deviasi 3.75 4.64 4.23 6.18 Variasi 14.05 21.53 17.93 38.18 Skewnes 0.08 0.02 0.08 -0 Quantile 1 21 30.75 25 24 Quantile 2 24 34 29 30 Quantile 3 27 39 32 35 Median 24 34 29 30 Modus 21 32 26 24 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Berikut penerapan statistik  deskriptif  di pyton"},{"location":"regresi/","text":"REGRESI BERGANDA \u00b6 regresi berganda adalah model regresi atau prediksi yang melibatkan lebih dari satu variabel bebas atau prediktor. Istilah regresi berganda dapat disebut juga dengan istilah multiple regression. Kata multiple berarti jamak atau lebih dari satu variabel. algoritma regresi berganda Y\u2019 = a + b1X1+ b2X2+\u2026..+ bnXn Keterangan: Y\u2019 = Variabel dependen (nilai yang diprediksikan) X1 dan X2 = Variabel independen a = Konstanta (nilai Y\u2019 apabila X1, X2\u2026..Xn = 0) b = Koefisien regresi (nilai peningkatan ataupun penurunan) berikut perhitungan manual exsel dowlod exsel disini implemetasi di pemograman python import numpy as np from sklearn.linear_model import LinearRegression X = np . array ([[ 2 , 3 ],[ 4 , 2 ],[ 5 , 3 ],[ 7 , 1 ]]) y = np . array ([ 10 , 12 , 16 , 16 ]) X array([[2, 3], [4, 2], [5, 3], [7, 1]]) reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) 1.0 a = reg . intercept_ a 7.105427357601002e-15 b2 = reg . coef_ [ 1 ] b1 = reg . coef_ [ 0 ] x1 = 6 x2 = 2 reg . coef_ array([2., 2.]) y = b1 * x1 + b2 * x2 + a y 16.0 import numpy as np from sklearn.linear_model import LinearRegression X = np . array ([[ 2 , 3 , 1 ],[ 4 , 2 , 2 ],[ 5 , 3 , 1 ],[ 7 , 1 , 1 ]]) y = np . array ([ 12 , 16 , 18 , 18 ]) X array([[2, 3, 1], [4, 2, 2], [5, 3, 1], [7, 1, 1]]) reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) 1.0 a = reg . intercept_ a 1.0658141036401503e-14 b3 = reg . coef_ [ 2 ] b2 = reg . coef_ [ 1 ] b1 = reg . coef_ [ 0 ] x1 = 6 x2 = 2 x3 = 2 reg . coef_ array([2., 2., 2.]) y = b1 * x1 + b2 * x2 + b3 * x3 + a y 19.999999999999996","title":"regresi berganda"},{"location":"regresi/#regresi-berganda","text":"regresi berganda adalah model regresi atau prediksi yang melibatkan lebih dari satu variabel bebas atau prediktor. Istilah regresi berganda dapat disebut juga dengan istilah multiple regression. Kata multiple berarti jamak atau lebih dari satu variabel. algoritma regresi berganda Y\u2019 = a + b1X1+ b2X2+\u2026..+ bnXn Keterangan: Y\u2019 = Variabel dependen (nilai yang diprediksikan) X1 dan X2 = Variabel independen a = Konstanta (nilai Y\u2019 apabila X1, X2\u2026..Xn = 0) b = Koefisien regresi (nilai peningkatan ataupun penurunan) berikut perhitungan manual exsel dowlod exsel disini implemetasi di pemograman python import numpy as np from sklearn.linear_model import LinearRegression X = np . array ([[ 2 , 3 ],[ 4 , 2 ],[ 5 , 3 ],[ 7 , 1 ]]) y = np . array ([ 10 , 12 , 16 , 16 ]) X array([[2, 3], [4, 2], [5, 3], [7, 1]]) reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) 1.0 a = reg . intercept_ a 7.105427357601002e-15 b2 = reg . coef_ [ 1 ] b1 = reg . coef_ [ 0 ] x1 = 6 x2 = 2 reg . coef_ array([2., 2.]) y = b1 * x1 + b2 * x2 + a y 16.0 import numpy as np from sklearn.linear_model import LinearRegression X = np . array ([[ 2 , 3 , 1 ],[ 4 , 2 , 2 ],[ 5 , 3 , 1 ],[ 7 , 1 , 1 ]]) y = np . array ([ 12 , 16 , 18 , 18 ]) X array([[2, 3, 1], [4, 2, 2], [5, 3, 1], [7, 1, 1]]) reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) 1.0 a = reg . intercept_ a 1.0658141036401503e-14 b3 = reg . coef_ [ 2 ] b2 = reg . coef_ [ 1 ] b1 = reg . coef_ [ 0 ] x1 = 6 x2 = 2 x3 = 2 reg . coef_ array([2., 2., 2.]) y = b1 * x1 + b2 * x2 + b3 * x3 + a y 19.999999999999996","title":"REGRESI BERGANDA"},{"location":"tugas1/","text":"Eror di komputasi numerik \u00b6 1.round-off error Perhitungan dengan metode numerik hampir selalu menggunakan bilangan riil.Masalah timbul apabila komputasi numerik dikerjakan oleh mesin (dalam hal ini dengan menggunakan komputer) karena semua bilangan riil tidak dapat disajikan secara tepat di dalam komputer 2. Truncation Error Kesalahan pemotongan terjadi ketika suatu rumus komputasi disederhanakan dengan cara membuang suku yang berderajat tinggi DEFINISI MACLAURIN \u00b6 Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret TaylorDefinisi. Berikut algoritma dari maclaurin \u00b6 Dengan algoritma diatas kita dapat menyerderhanakannya sebagai berikut: berikut contoh implementai dari maclaurin f(x)= e 2x $$ f(x)\u22481+2x \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ sekarang kita masukan misal x=0 $$ f(0)\u22481+2(0) \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ jadi ketika x =0 maka hasil akan tetap 1 mekipun banyak suku dan literasi Listing Program \u00b6 membuat program supaya dapaat mengekspansi bilangan e^3x dengan nilai x=inputan hingga nilai menjadi kurang dari 0,001 bisa dengan listing program sebagai berikut. import math x = int ( input ( \"masukan nilai x=\" )) coba = 1 a = 0 b = 1 while coba > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 3 ** i ) * x ** i / math . factorial ( i ) for j in range ( b ): f_y += ( 3 ** j ) * x ** j / math . factorial ( j ) print ( \"suku ke\" , a , \"=\" , f_x ) print ( \"suku ke\" , b , \"=\" , f_y ) coba = f_y - f_x a += 1 b += 1 print ( \"hasil seliih =\" , coba ) output: masukan nilai x = 1 suku ke 0 = 0 suku ke 1 = 1.0 hasil seliih = 1.0 suku ke 1 = 1.0 suku ke 2 = 4.0 hasil seliih = 3.0 suku ke 2 = 4.0 suku ke 3 = 8.5 hasil seliih = 4.5 suku ke 3 = 8.5 suku ke 4 = 13.0 hasil seliih = 4.5 suku ke 4 = 13.0 suku ke 5 = 16.375 hasil seliih = 3.375 suku ke 5 = 16.375 suku ke 6 = 18.4 hasil seliih = 2.0249999999999986 suku ke 6 = 18.4 suku ke 7 = 19.412499999999998 hasil seliih = 1.0124999999999993 suku ke 7 = 19.412499999999998 suku ke 8 = 19.846428571428568 hasil seliih = 0.4339285714285701 suku ke 8 = 19.846428571428568 suku ke 9 = 20.009151785714284 hasil seliih = 0.162723214285716 suku ke 9 = 20.009151785714284 suku ke 10 = 20.063392857142855 hasil seliih = 0.05424107142857082 suku ke 10 = 20.063392857142855 suku ke 11 = 20.079665178571425 hasil seliih = 0.016272321428569825 suku ke 11 = 20.079665178571425 suku ke 12 = 20.08410308441558 hasil seliih = 0.004437905844156376 suku ke 12 = 20.08410308441558 suku ke 13 = 20.08521256087662 hasil seliih = 0.001109476461039094 suku ke 13 = 20.08521256087662 suku ke 14 = 20.08546859390609 hasil seliih = 0.0002560330294691937 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"error"},{"location":"tugas1/#eror-di-komputasi-numerik","text":"1.round-off error Perhitungan dengan metode numerik hampir selalu menggunakan bilangan riil.Masalah timbul apabila komputasi numerik dikerjakan oleh mesin (dalam hal ini dengan menggunakan komputer) karena semua bilangan riil tidak dapat disajikan secara tepat di dalam komputer 2. Truncation Error Kesalahan pemotongan terjadi ketika suatu rumus komputasi disederhanakan dengan cara membuang suku yang berderajat tinggi","title":"Eror di komputasi numerik"},{"location":"tugas1/#definisi-maclaurin","text":"Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret TaylorDefinisi.","title":"DEFINISI MACLAURIN"},{"location":"tugas1/#berikut-algoritma-dari-maclaurin","text":"Dengan algoritma diatas kita dapat menyerderhanakannya sebagai berikut: berikut contoh implementai dari maclaurin f(x)= e 2x $$ f(x)\u22481+2x \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{f}^{{\\text{}}}{\\left({2x^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ sekarang kita masukan misal x=0 $$ f(0)\u22481+2(0) \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^2}\\right)}}}}{{{3}!}} \\displaystyle+\\frac{{{{}^{{\\text{}}}{\\left({2(0)^3}\\right)}}}}{{{3}!}} \\displaystyle+\\ldots+\u2026 $$ jadi ketika x =0 maka hasil akan tetap 1 mekipun banyak suku dan literasi","title":"Berikut algoritma dari maclaurin"},{"location":"tugas1/#listing-program","text":"membuat program supaya dapaat mengekspansi bilangan e^3x dengan nilai x=inputan hingga nilai menjadi kurang dari 0,001 bisa dengan listing program sebagai berikut. import math x = int ( input ( \"masukan nilai x=\" )) coba = 1 a = 0 b = 1 while coba > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 3 ** i ) * x ** i / math . factorial ( i ) for j in range ( b ): f_y += ( 3 ** j ) * x ** j / math . factorial ( j ) print ( \"suku ke\" , a , \"=\" , f_x ) print ( \"suku ke\" , b , \"=\" , f_y ) coba = f_y - f_x a += 1 b += 1 print ( \"hasil seliih =\" , coba ) output: masukan nilai x = 1 suku ke 0 = 0 suku ke 1 = 1.0 hasil seliih = 1.0 suku ke 1 = 1.0 suku ke 2 = 4.0 hasil seliih = 3.0 suku ke 2 = 4.0 suku ke 3 = 8.5 hasil seliih = 4.5 suku ke 3 = 8.5 suku ke 4 = 13.0 hasil seliih = 4.5 suku ke 4 = 13.0 suku ke 5 = 16.375 hasil seliih = 3.375 suku ke 5 = 16.375 suku ke 6 = 18.4 hasil seliih = 2.0249999999999986 suku ke 6 = 18.4 suku ke 7 = 19.412499999999998 hasil seliih = 1.0124999999999993 suku ke 7 = 19.412499999999998 suku ke 8 = 19.846428571428568 hasil seliih = 0.4339285714285701 suku ke 8 = 19.846428571428568 suku ke 9 = 20.009151785714284 hasil seliih = 0.162723214285716 suku ke 9 = 20.009151785714284 suku ke 10 = 20.063392857142855 hasil seliih = 0.05424107142857082 suku ke 10 = 20.063392857142855 suku ke 11 = 20.079665178571425 hasil seliih = 0.016272321428569825 suku ke 11 = 20.079665178571425 suku ke 12 = 20.08410308441558 hasil seliih = 0.004437905844156376 suku ke 12 = 20.08410308441558 suku ke 13 = 20.08521256087662 hasil seliih = 0.001109476461039094 suku ke 13 = 20.08521256087662 suku ke 14 = 20.08546859390609 hasil seliih = 0.0002560330294691937 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Listing Program"}]}